{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from efficientnet.keras import EfficientNetB5\n",
    "from keras_squeeze_excite_network.se_resnext import SEResNextImageNet as SEResNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(120, 120)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def upper(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training))\n",
    "         \n",
    "        \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            #imgs = [randomErase(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiBased():\n",
    "    model =  EfficientNetB5(weights=\"imagenet\", include_top=False, input_shape=(*size, 3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Dense(1024, activation=\"relu\")(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236), y, train_size=0.9, random_state=8000)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-eff5-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n",
      "Epoch 1/80\n",
      "2824/2825 [============================>.] - ETA: 0s - loss: 1.8811 - dense_1_loss: 2.7954 - dense_2_loss: 1.2009 - dense_3_loss: 0.7327 - dense_1_acc: 0.5118 - dense_2_acc: 0.6891 - dense_3_acc: 0.7904Epoch 1/80\n",
      "2825/2825 [==============================] - 1706s 604ms/step - loss: 1.8810 - dense_1_loss: 2.7952 - dense_2_loss: 1.2008 - dense_3_loss: 0.7327 - dense_1_acc: 0.5118 - dense_2_acc: 0.6891 - dense_3_acc: 0.7904 - val_loss: 0.3212 - val_dense_1_loss: 0.4106 - val_dense_2_loss: 0.1470 - val_dense_3_loss: 0.1279 - val_dense_1_acc: 0.8886 - val_dense_2_acc: 0.9610 - val_dense_3_acc: 0.9631\n",
      "Epoch 2/80\n",
      "2825/2825 [==============================] - 1543s 546ms/step - loss: 1.3943 - dense_1_loss: 1.9821 - dense_2_loss: 0.9925 - dense_3_loss: 0.6203 - dense_1_acc: 0.6116 - dense_2_acc: 0.7202 - dense_3_acc: 0.8098 - val_loss: 0.1689 - val_dense_1_loss: 0.2974 - val_dense_2_loss: 0.1264 - val_dense_3_loss: 0.1310 - val_dense_1_acc: 0.9157 - val_dense_2_acc: 0.9666 - val_dense_3_acc: 0.9641\n",
      "Epoch 3/80\n",
      "2825/2825 [==============================] - 1487s 526ms/step - loss: 1.2319 - dense_1_loss: 1.7091 - dense_2_loss: 0.9225 - dense_3_loss: 0.5870 - dense_1_acc: 0.6293 - dense_2_acc: 0.7382 - dense_3_acc: 0.8204 - val_loss: 0.1677 - val_dense_1_loss: 0.2531 - val_dense_2_loss: 0.0958 - val_dense_3_loss: 0.1005 - val_dense_1_acc: 0.9298 - val_dense_2_acc: 0.9760 - val_dense_3_acc: 0.9717\n",
      "Epoch 4/80\n",
      "2825/2825 [==============================] - 1442s 511ms/step - loss: 1.1410 - dense_1_loss: 1.5588 - dense_2_loss: 0.8783 - dense_3_loss: 0.5681 - dense_1_acc: 0.6452 - dense_2_acc: 0.7567 - dense_3_acc: 0.8282 - val_loss: 0.1405 - val_dense_1_loss: 0.2479 - val_dense_2_loss: 0.0956 - val_dense_3_loss: 0.0961 - val_dense_1_acc: 0.9309 - val_dense_2_acc: 0.9738 - val_dense_3_acc: 0.9714\n",
      "Epoch 5/80\n",
      "1130/2825 [===========>..................] - ETA: 13:47 - loss: 1.0917 - dense_1_loss: 1.4807 - dense_2_loss: 0.8557 - dense_3_loss: 0.5499 - dense_1_acc: 0.6535 - dense_2_acc: 0.7683 - dense_3_acc: 0.8360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2825 [==============================] - 1444s 511ms/step - loss: 0.9936 - dense_1_loss: 1.3286 - dense_2_loss: 0.7890 - dense_3_loss: 0.5283 - dense_1_acc: 0.6715 - dense_2_acc: 0.7927 - dense_3_acc: 0.8459 - val_loss: 0.1889 - val_dense_1_loss: 0.2084 - val_dense_2_loss: 0.0717 - val_dense_3_loss: 0.0772 - val_dense_1_acc: 0.9429 - val_dense_2_acc: 0.9828 - val_dense_3_acc: 0.9760\n",
      "Epoch 8/80\n",
      "2825/2825 [==============================] - 1445s 512ms/step - loss: 0.9647 - dense_1_loss: 1.2846 - dense_2_loss: 0.7684 - dense_3_loss: 0.5211 - dense_1_acc: 0.6761 - dense_2_acc: 0.7989 - dense_3_acc: 0.8512 - val_loss: 0.1272 - val_dense_1_loss: 0.2220 - val_dense_2_loss: 0.0790 - val_dense_3_loss: 0.0713 - val_dense_1_acc: 0.9408 - val_dense_2_acc: 0.9795 - val_dense_3_acc: 0.9808\n",
      "Epoch 9/80\n",
      "2825/2825 [==============================] - 1448s 513ms/step - loss: 0.9394 - dense_1_loss: 1.2460 - dense_2_loss: 0.7509 - dense_3_loss: 0.5144 - dense_1_acc: 0.6825 - dense_2_acc: 0.8036 - dense_3_acc: 0.8531 - val_loss: 0.0940 - val_dense_1_loss: 0.2020 - val_dense_2_loss: 0.0765 - val_dense_3_loss: 0.0685 - val_dense_1_acc: 0.9463 - val_dense_2_acc: 0.9801 - val_dense_3_acc: 0.9808\n",
      "Epoch 10/80\n",
      "2825/2825 [==============================] - 1446s 512ms/step - loss: 0.9195 - dense_1_loss: 1.2152 - dense_2_loss: 0.7408 - dense_3_loss: 0.5066 - dense_1_acc: 0.6878 - dense_2_acc: 0.8089 - dense_3_acc: 0.8581 - val_loss: 0.1221 - val_dense_1_loss: 0.1961 - val_dense_2_loss: 0.0703 - val_dense_3_loss: 0.0639 - val_dense_1_acc: 0.9457 - val_dense_2_acc: 0.9817 - val_dense_3_acc: 0.9828\n",
      "Epoch 11/80\n",
      "2825/2825 [==============================] - 1446s 512ms/step - loss: 0.9020 - dense_1_loss: 1.1884 - dense_2_loss: 0.7300 - dense_3_loss: 0.5012 - dense_1_acc: 0.6886 - dense_2_acc: 0.8108 - dense_3_acc: 0.8615 - val_loss: 0.1121 - val_dense_1_loss: 0.1888 - val_dense_2_loss: 0.0691 - val_dense_3_loss: 0.0642 - val_dense_1_acc: 0.9469 - val_dense_2_acc: 0.9817 - val_dense_3_acc: 0.9821\n",
      "Epoch 12/80\n",
      "2825/2825 [==============================] - 1448s 513ms/step - loss: 0.8866 - dense_1_loss: 1.1641 - dense_2_loss: 0.7217 - dense_3_loss: 0.4966 - dense_1_acc: 0.6958 - dense_2_acc: 0.8146 - dense_3_acc: 0.8635 - val_loss: 0.0982 - val_dense_1_loss: 0.1988 - val_dense_2_loss: 0.0616 - val_dense_3_loss: 0.0702 - val_dense_1_acc: 0.9472 - val_dense_2_acc: 0.9847 - val_dense_3_acc: 0.9816\n",
      "Epoch 13/80\n",
      "2825/2825 [==============================] - 1445s 511ms/step - loss: 0.8723 - dense_1_loss: 1.1417 - dense_2_loss: 0.7137 - dense_3_loss: 0.4922 - dense_1_acc: 0.6977 - dense_2_acc: 0.8180 - dense_3_acc: 0.8665 - val_loss: 0.1261 - val_dense_1_loss: 0.1874 - val_dense_2_loss: 0.0644 - val_dense_3_loss: 0.0600 - val_dense_1_acc: 0.9510 - val_dense_2_acc: 0.9839 - val_dense_3_acc: 0.9842\n",
      "Epoch 14/80\n",
      "2825/2825 [==============================] - 1448s 513ms/step - loss: 0.8616 - dense_1_loss: 1.1263 - dense_2_loss: 0.7074 - dense_3_loss: 0.4864 - dense_1_acc: 0.7009 - dense_2_acc: 0.8215 - dense_3_acc: 0.8684 - val_loss: 0.1318 - val_dense_1_loss: 0.1866 - val_dense_2_loss: 0.0700 - val_dense_3_loss: 0.0601 - val_dense_1_acc: 0.9501 - val_dense_2_acc: 0.9825 - val_dense_3_acc: 0.9832\n",
      "Epoch 15/80\n",
      "2825/2825 [==============================] - 1444s 511ms/step - loss: 0.8483 - dense_1_loss: 1.1034 - dense_2_loss: 0.7022 - dense_3_loss: 0.4840 - dense_1_acc: 0.7063 - dense_2_acc: 0.8229 - dense_3_acc: 0.8716 - val_loss: 0.1323 - val_dense_1_loss: 0.1861 - val_dense_2_loss: 0.0627 - val_dense_3_loss: 0.0574 - val_dense_1_acc: 0.9488 - val_dense_2_acc: 0.9843 - val_dense_3_acc: 0.9850\n",
      "Epoch 16/80\n",
      "2825/2825 [==============================] - 1446s 512ms/step - loss: 0.8392 - dense_1_loss: 1.0912 - dense_2_loss: 0.6958 - dense_3_loss: 0.4787 - dense_1_acc: 0.7081 - dense_2_acc: 0.8269 - dense_3_acc: 0.8730 - val_loss: 0.1221 - val_dense_1_loss: 0.1815 - val_dense_2_loss: 0.0733 - val_dense_3_loss: 0.0640 - val_dense_1_acc: 0.9491 - val_dense_2_acc: 0.9808 - val_dense_3_acc: 0.9824\n",
      "Epoch 17/80\n",
      "2825/2825 [==============================] - 1443s 511ms/step - loss: 0.8315 - dense_1_loss: 1.0781 - dense_2_loss: 0.6920 - dense_3_loss: 0.4777 - dense_1_acc: 0.7106 - dense_2_acc: 0.8291 - dense_3_acc: 0.8751 - val_loss: 0.1585 - val_dense_1_loss: 0.1757 - val_dense_2_loss: 0.0616 - val_dense_3_loss: 0.0531 - val_dense_1_acc: 0.9504 - val_dense_2_acc: 0.9851 - val_dense_3_acc: 0.9856\n",
      "Epoch 18/80\n",
      "2825/2825 [==============================] - 1445s 512ms/step - loss: 0.8220 - dense_1_loss: 1.0641 - dense_2_loss: 0.6859 - dense_3_loss: 0.4738 - dense_1_acc: 0.7122 - dense_2_acc: 0.8332 - dense_3_acc: 0.8775 - val_loss: 0.1675 - val_dense_1_loss: 0.1719 - val_dense_2_loss: 0.0600 - val_dense_3_loss: 0.0562 - val_dense_1_acc: 0.9529 - val_dense_2_acc: 0.9847 - val_dense_3_acc: 0.9844\n",
      "Epoch 19/80\n",
      "2235/2825 [======================>.......] - ETA: 4:48 - loss: 0.8145 - dense_1_loss: 1.0522 - dense_2_loss: 0.6831 - dense_3_loss: 0.4703 - dense_1_acc: 0.7150 - dense_2_acc: 0.8341 - dense_3_acc: 0.8801"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=batch_size, size=size)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=batch_size, size=size)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "#model.summary()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.5,0.25,0.25])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=80, callbacks=[checkpoint], workers=64, use_multiprocessing=True)\n",
    "model.save(\"multiEfficientNetB5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
