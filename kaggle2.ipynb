{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169\n",
    "import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(224,224)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def upper(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def rotateImg(img, angle=None,prob=True):\n",
    "    if prob==False or np.random.random()<0.5:\n",
    "        if angle==None:\n",
    "            angle=np.random.random()*60-30\n",
    "        trans = cv2.getRotationMatrix2D((img.shape[0]/2, img.shape[1]/2), angle , 1.0)\n",
    "        img = cv2.warpAffine(img, trans, (img.shape[1],img.shape[0]))\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def shiftImg(img, prob=True):\n",
    "    if prob==False or np.random.random()<0.5:\n",
    "        x=np.random.random()*30-15\n",
    "        y=np.random.random()*30-15\n",
    "        trans = np.float32([[1,0,x],[0,1,y]])\n",
    "        img = cv2.warpAffine(img, trans, (img.shape[1],img.shape[0]))\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255)):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training))\n",
    "         \n",
    "        \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training and np.random.random()<0.4:\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            alpha=np.random.random(imgs.shape[0])\n",
    "            alpha[alpha>1]=1\n",
    "            alpha[alpha<0]=0\n",
    "            imgs=np.tile(alpha,(3,*size,1)).T*imgs+np.tile((1-alpha),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(alpha,(168,1)).T*grapheme+np.tile((1-alpha),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(alpha,(11,1)).T*vowel+np.tile((1-alpha),(11,1)).T*vowel2\n",
    "            consonant=np.tile(alpha,(7,1)).T*consonant+np.tile((1-alpha),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def getMultiBased():\n",
    "    model =  ResNet152V2(weights=\"imagenet\", include_top=False)\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model\n",
    "    \"\"\"\n",
    "\n",
    "def getMultiBased():\n",
    "    feature_extractor_url = \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\"\n",
    "    feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(*size,3))\n",
    "    model=Sequential([feature_extractor_layer])\n",
    "    x=model.output\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236),y,train_size=0.9,random_state=8000)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-eff-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "WARNING:tensorflow:From /usr/local/bin/python/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/bin/python/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n",
      "Train for 2825 steps, validate for 314 steps\n",
      "Epoch 1/80\n",
      "2825/2825 [==============================] - 723s 256ms/step - loss: 3.0870 - dense_loss: 3.5989 - dense_1_loss: 1.2224 - dense_2_loss: 0.8555 - dense_acc: 0.2013 - dense_1_acc: 0.6032 - dense_2_acc: 0.6963 - val_loss: 2.4389 - val_dense_loss: 2.8705 - val_dense_1_loss: 0.7799 - val_dense_2_loss: 0.6450 - val_dense_acc: 0.3184 - val_dense_1_acc: 0.7458 - val_dense_2_acc: 0.7643\n",
      "Epoch 2/80\n",
      "2825/2825 [==============================] - 721s 255ms/step - loss: 2.6448 - dense_loss: 3.0805 - dense_1_loss: 1.0457 - dense_2_loss: 0.7581 - dense_acc: 0.2946 - dense_1_acc: 0.6691 - dense_2_acc: 0.7338 - val_loss: 2.1942 - val_dense_loss: 2.5807 - val_dense_1_loss: 0.7049 - val_dense_2_loss: 0.5912 - val_dense_acc: 0.3690 - val_dense_1_acc: 0.7694 - val_dense_2_acc: 0.7976\n",
      "Epoch 3/80\n",
      "2825/2825 [==============================] - 734s 260ms/step - loss: 2.5112 - dense_loss: 2.9203 - dense_1_loss: 1.0130 - dense_2_loss: 0.7364 - dense_acc: 0.3300 - dense_1_acc: 0.6806 - dense_2_acc: 0.7430 - val_loss: 2.0507 - val_dense_loss: 2.4079 - val_dense_1_loss: 0.6746 - val_dense_2_loss: 0.5689 - val_dense_acc: 0.4026 - val_dense_1_acc: 0.7787 - val_dense_2_acc: 0.8002\n",
      "Epoch 4/80\n",
      "2825/2825 [==============================] - 741s 262ms/step - loss: 2.4334 - dense_loss: 2.8264 - dense_1_loss: 0.9975 - dense_2_loss: 0.7250 - dense_acc: 0.3506 - dense_1_acc: 0.6876 - dense_2_acc: 0.7476 - val_loss: 1.9594 - val_dense_loss: 2.3004 - val_dense_1_loss: 0.6429 - val_dense_2_loss: 0.5486 - val_dense_acc: 0.4205 - val_dense_1_acc: 0.7856 - val_dense_2_acc: 0.8082\n",
      "Epoch 5/80\n",
      " 565/2825 [=====>........................] - ETA: 10:39 - loss: 2.3912 - dense_loss: 2.7759 - dense_1_loss: 0.9832 - dense_2_loss: 0.7211 - dense_acc: 0.3592 - dense_1_acc: 0.6916 - dense_2_acc: 0.7487"
     ]
    }
   ],
   "source": [
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=64,size=size)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=64,size=size)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.8,0.1,0.1])\n",
    "print(\"compiled\")\n",
    "model.fit(train_gen, validation_data=valid_gen, epochs=80, callbacks=[checkpoint])\n",
    "model.save(\"multiEfficient.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
