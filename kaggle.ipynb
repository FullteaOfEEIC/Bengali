{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from efficientnet.keras import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(120, 120)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def upper(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True,clahe=False):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    if clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "    img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3,clahe=True):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "        self.clahe=clahe\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training,clahe=self.clahe))\n",
    "         \n",
    "        \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            imgs = [randomErase(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiBased():\n",
    "    model =  Xception(weights=\"imagenet\", include_top=False,input_shape=(*size,3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Dense(1024, activation=\"relu\")(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236),y,train_size=0.9,random_state=8000)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-xce-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 59, 59, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 59, 59, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 59, 59, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 57, 57, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 57, 57, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 57, 57, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 57, 57, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 57, 57, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 57, 57, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 29, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 29, 29, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 29, 29, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 29, 29, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 29, 29, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 29, 29, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 29, 29, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 29, 29, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 15, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 15, 15, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15, 15, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 15, 15, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 15, 15, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 15, 15, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 15, 15, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 168)          344232      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           22539       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            14343       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,242,594\n",
      "Trainable params: 21,188,066\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "707/707 [==============================] - 675s 954ms/step - loss: 1.2688 - dense_1_loss: 1.9488 - dense_2_loss: 0.7045 - dense_3_loss: 0.4729 - dense_1_acc: 0.5756 - dense_2_acc: 0.8052 - dense_3_acc: 0.8645 - val_loss: 0.3300 - val_dense_1_loss: 0.4595 - val_dense_2_loss: 0.1391 - val_dense_3_loss: 0.1138 - val_dense_1_acc: 0.8690 - val_dense_2_acc: 0.9592 - val_dense_3_acc: 0.9643\n",
      "Epoch 2/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.8270 - dense_1_loss: 1.2413 - dense_2_loss: 0.4970 - dense_3_loss: 0.3285 - dense_1_acc: 0.7512 - dense_2_acc: 0.8821 - dense_3_acc: 0.9153 - val_loss: 0.1945 - val_dense_1_loss: 0.3160 - val_dense_2_loss: 0.0943 - val_dense_3_loss: 0.0859 - val_dense_1_acc: 0.9131 - val_dense_2_acc: 0.9739 - val_dense_3_acc: 0.9742\n",
      "Epoch 3/80\n",
      "707/707 [==============================] - 625s 883ms/step - loss: 0.7513 - dense_1_loss: 1.1241 - dense_2_loss: 0.4554 - dense_3_loss: 0.3015 - dense_1_acc: 0.7810 - dense_2_acc: 0.8957 - dense_3_acc: 0.9253 - val_loss: 0.2152 - val_dense_1_loss: 0.3335 - val_dense_2_loss: 0.1145 - val_dense_3_loss: 0.0923 - val_dense_1_acc: 0.9037 - val_dense_2_acc: 0.9663 - val_dense_3_acc: 0.9708\n",
      "Epoch 4/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.7129 - dense_1_loss: 1.0646 - dense_2_loss: 0.4343 - dense_3_loss: 0.2880 - dense_1_acc: 0.7943 - dense_2_acc: 0.9015 - dense_3_acc: 0.9293 - val_loss: 0.1666 - val_dense_1_loss: 0.2831 - val_dense_2_loss: 0.0781 - val_dense_3_loss: 0.0782 - val_dense_1_acc: 0.9198 - val_dense_2_acc: 0.9789 - val_dense_3_acc: 0.9769\n",
      "Epoch 5/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.6822 - dense_1_loss: 1.0173 - dense_2_loss: 0.4167 - dense_3_loss: 0.2773 - dense_1_acc: 0.8049 - dense_2_acc: 0.9076 - dense_3_acc: 0.9318 - val_loss: 0.1749 - val_dense_1_loss: 0.2662 - val_dense_2_loss: 0.0809 - val_dense_3_loss: 0.0686 - val_dense_1_acc: 0.9248 - val_dense_2_acc: 0.9784 - val_dense_3_acc: 0.9802\n",
      "Epoch 6/80\n",
      "707/707 [==============================] - 626s 885ms/step - loss: 0.6598 - dense_1_loss: 0.9852 - dense_2_loss: 0.4024 - dense_3_loss: 0.2662 - dense_1_acc: 0.8127 - dense_2_acc: 0.9103 - dense_3_acc: 0.9358 - val_loss: 0.1229 - val_dense_1_loss: 0.2482 - val_dense_2_loss: 0.0671 - val_dense_3_loss: 0.0646 - val_dense_1_acc: 0.9306 - val_dense_2_acc: 0.9829 - val_dense_3_acc: 0.9808\n",
      "Epoch 7/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.6365 - dense_1_loss: 0.9456 - dense_2_loss: 0.3936 - dense_3_loss: 0.2610 - dense_1_acc: 0.8210 - dense_2_acc: 0.9121 - dense_3_acc: 0.9371 - val_loss: 0.2004 - val_dense_1_loss: 0.2945 - val_dense_2_loss: 0.0825 - val_dense_3_loss: 0.0728 - val_dense_1_acc: 0.9205 - val_dense_2_acc: 0.9796 - val_dense_3_acc: 0.9806\n",
      "Epoch 8/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.6263 - dense_1_loss: 0.9315 - dense_2_loss: 0.3859 - dense_3_loss: 0.2561 - dense_1_acc: 0.8243 - dense_2_acc: 0.9138 - dense_3_acc: 0.9385 - val_loss: 0.1408 - val_dense_1_loss: 0.2240 - val_dense_2_loss: 0.0657 - val_dense_3_loss: 0.0542 - val_dense_1_acc: 0.9390 - val_dense_2_acc: 0.9832 - val_dense_3_acc: 0.9857\n",
      "Epoch 9/80\n",
      "707/707 [==============================] - ETA: 0s - loss: 0.6097 - dense_1_loss: 0.9059 - dense_2_loss: 0.3753 - dense_3_loss: 0.2518 - dense_1_acc: 0.8284 - dense_2_acc: 0.9158 - dense_3_acc: 0.93 - 627s 886ms/step - loss: 0.6097 - dense_1_loss: 0.9059 - dense_2_loss: 0.3753 - dense_3_loss: 0.2518 - dense_1_acc: 0.8284 - dense_2_acc: 0.9158 - dense_3_acc: 0.9398 - val_loss: 0.1353 - val_dense_1_loss: 0.2224 - val_dense_2_loss: 0.0767 - val_dense_3_loss: 0.0612 - val_dense_1_acc: 0.9400 - val_dense_2_acc: 0.9817 - val_dense_3_acc: 0.9824\n",
      "Epoch 10/80\n",
      "707/707 [==============================] - 627s 886ms/step - loss: 0.5943 - dense_1_loss: 0.8814 - dense_2_loss: 0.3687 - dense_3_loss: 0.2458 - dense_1_acc: 0.8340 - dense_2_acc: 0.9184 - dense_3_acc: 0.9411 - val_loss: 0.1474 - val_dense_1_loss: 0.2131 - val_dense_2_loss: 0.0615 - val_dense_3_loss: 0.0562 - val_dense_1_acc: 0.9425 - val_dense_2_acc: 0.9844 - val_dense_3_acc: 0.9846\n",
      "Epoch 11/80\n",
      "707/707 [==============================] - 635s 899ms/step - loss: 0.5867 - dense_1_loss: 0.8696 - dense_2_loss: 0.3656 - dense_3_loss: 0.2422 - dense_1_acc: 0.8359 - dense_2_acc: 0.9187 - dense_3_acc: 0.9420 - val_loss: 0.1659 - val_dense_1_loss: 0.2042 - val_dense_2_loss: 0.0582 - val_dense_3_loss: 0.0598 - val_dense_1_acc: 0.9439 - val_dense_2_acc: 0.9856 - val_dense_3_acc: 0.9838\n",
      "Epoch 12/80\n",
      "707/707 [==============================] - 636s 900ms/step - loss: 0.5744 - dense_1_loss: 0.8506 - dense_2_loss: 0.3588 - dense_3_loss: 0.2378 - dense_1_acc: 0.8396 - dense_2_acc: 0.9194 - dense_3_acc: 0.9440 - val_loss: 0.1191 - val_dense_1_loss: 0.2125 - val_dense_2_loss: 0.0674 - val_dense_3_loss: 0.0582 - val_dense_1_acc: 0.9429 - val_dense_2_acc: 0.9828 - val_dense_3_acc: 0.9838\n",
      "Epoch 13/80\n",
      "707/707 [==============================] - 635s 899ms/step - loss: 0.5625 - dense_1_loss: 0.8333 - dense_2_loss: 0.3502 - dense_3_loss: 0.2333 - dense_1_acc: 0.8429 - dense_2_acc: 0.9218 - dense_3_acc: 0.9447 - val_loss: 0.1560 - val_dense_1_loss: 0.2109 - val_dense_2_loss: 0.0597 - val_dense_3_loss: 0.0593 - val_dense_1_acc: 0.9421 - val_dense_2_acc: 0.9836 - val_dense_3_acc: 0.9833\n",
      "Epoch 14/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.5551 - dense_1_loss: 0.8210 - dense_2_loss: 0.3469 - dense_3_loss: 0.2315 - dense_1_acc: 0.8440 - dense_2_acc: 0.9226 - dense_3_acc: 0.9449 - val_loss: 0.1690 - val_dense_1_loss: 0.2034 - val_dense_2_loss: 0.0598 - val_dense_3_loss: 0.0549 - val_dense_1_acc: 0.9444 - val_dense_2_acc: 0.9846 - val_dense_3_acc: 0.9848\n",
      "Epoch 15/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.5443 - dense_1_loss: 0.8024 - dense_2_loss: 0.3431 - dense_3_loss: 0.2291 - dense_1_acc: 0.8490 - dense_2_acc: 0.9236 - dense_3_acc: 0.9462 - val_loss: 0.1478 - val_dense_1_loss: 0.1947 - val_dense_2_loss: 0.0590 - val_dense_3_loss: 0.0536 - val_dense_1_acc: 0.9482 - val_dense_2_acc: 0.9849 - val_dense_3_acc: 0.9853\n",
      "Epoch 16/80\n",
      "707/707 [==============================] - 627s 886ms/step - loss: 0.5377 - dense_1_loss: 0.7923 - dense_2_loss: 0.3386 - dense_3_loss: 0.2275 - dense_1_acc: 0.8506 - dense_2_acc: 0.9250 - dense_3_acc: 0.9466 - val_loss: 0.0876 - val_dense_1_loss: 0.1911 - val_dense_2_loss: 0.0596 - val_dense_3_loss: 0.0558 - val_dense_1_acc: 0.9452 - val_dense_2_acc: 0.9839 - val_dense_3_acc: 0.9845\n",
      "Epoch 17/80\n",
      "707/707 [==============================] - 643s 910ms/step - loss: 0.5253 - dense_1_loss: 0.7741 - dense_2_loss: 0.3320 - dense_3_loss: 0.2208 - dense_1_acc: 0.8541 - dense_2_acc: 0.9262 - dense_3_acc: 0.9484 - val_loss: 0.1185 - val_dense_1_loss: 0.1930 - val_dense_2_loss: 0.0569 - val_dense_3_loss: 0.0528 - val_dense_1_acc: 0.9462 - val_dense_2_acc: 0.9865 - val_dense_3_acc: 0.9868\n",
      "Epoch 18/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 0.5195 - dense_1_loss: 0.7655 - dense_2_loss: 0.3266 - dense_3_loss: 0.2203 - dense_1_acc: 0.8569 - dense_2_acc: 0.9276 - dense_3_acc: 0.9484 - val_loss: 0.1365 - val_dense_1_loss: 0.1959 - val_dense_2_loss: 0.0536 - val_dense_3_loss: 0.0516 - val_dense_1_acc: 0.9483 - val_dense_2_acc: 0.9868 - val_dense_3_acc: 0.9864\n",
      "Epoch 19/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.5188 - dense_1_loss: 0.7644 - dense_2_loss: 0.3274 - dense_3_loss: 0.2190 - dense_1_acc: 0.8555 - dense_2_acc: 0.9278 - dense_3_acc: 0.9488 - val_loss: 0.1574 - val_dense_1_loss: 0.2056 - val_dense_2_loss: 0.0623 - val_dense_3_loss: 0.0546 - val_dense_1_acc: 0.9505 - val_dense_2_acc: 0.9855 - val_dense_3_acc: 0.9871\n",
      "Epoch 20/80\n",
      "707/707 [==============================] - 657s 930ms/step - loss: 0.5070 - dense_1_loss: 0.7458 - dense_2_loss: 0.3225 - dense_3_loss: 0.2138 - dense_1_acc: 0.8592 - dense_2_acc: 0.9286 - dense_3_acc: 0.9502 - val_loss: 0.1164 - val_dense_1_loss: 0.1967 - val_dense_2_loss: 0.0562 - val_dense_3_loss: 0.0542 - val_dense_1_acc: 0.9505 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9860\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 664s 939ms/step - loss: 0.5000 - dense_1_loss: 0.7342 - dense_2_loss: 0.3185 - dense_3_loss: 0.2132 - dense_1_acc: 0.8614 - dense_2_acc: 0.9291 - dense_3_acc: 0.9502 - val_loss: 0.0994 - val_dense_1_loss: 0.1886 - val_dense_2_loss: 0.0562 - val_dense_3_loss: 0.0493 - val_dense_1_acc: 0.9503 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9871\n",
      "Epoch 22/80\n",
      "707/707 [==============================] - 632s 893ms/step - loss: 0.4951 - dense_1_loss: 0.7258 - dense_2_loss: 0.3167 - dense_3_loss: 0.2123 - dense_1_acc: 0.8634 - dense_2_acc: 0.9296 - dense_3_acc: 0.9506 - val_loss: 0.1472 - val_dense_1_loss: 0.1936 - val_dense_2_loss: 0.0561 - val_dense_3_loss: 0.0535 - val_dense_1_acc: 0.9493 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9850\n",
      "Epoch 23/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.4901 - dense_1_loss: 0.7191 - dense_2_loss: 0.3136 - dense_3_loss: 0.2083 - dense_1_acc: 0.8648 - dense_2_acc: 0.9310 - dense_3_acc: 0.9521 - val_loss: 0.1416 - val_dense_1_loss: 0.1806 - val_dense_2_loss: 0.0505 - val_dense_3_loss: 0.0481 - val_dense_1_acc: 0.9523 - val_dense_2_acc: 0.9874 - val_dense_3_acc: 0.9868\n",
      "Epoch 24/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 0.4786 - dense_1_loss: 0.7010 - dense_2_loss: 0.3063 - dense_3_loss: 0.2059 - dense_1_acc: 0.8678 - dense_2_acc: 0.9327 - dense_3_acc: 0.9526 - val_loss: 0.1188 - val_dense_1_loss: 0.2042 - val_dense_2_loss: 0.0593 - val_dense_3_loss: 0.0561 - val_dense_1_acc: 0.9505 - val_dense_2_acc: 0.9864 - val_dense_3_acc: 0.9866\n",
      "Epoch 26/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4739 - dense_1_loss: 0.6928 - dense_2_loss: 0.3058 - dense_3_loss: 0.2043 - dense_1_acc: 0.8701 - dense_2_acc: 0.9325 - dense_3_acc: 0.9531 - val_loss: 0.1039 - val_dense_1_loss: 0.1832 - val_dense_2_loss: 0.0612 - val_dense_3_loss: 0.0513 - val_dense_1_acc: 0.9500 - val_dense_2_acc: 0.9849 - val_dense_3_acc: 0.9862\n",
      "Epoch 27/80\n",
      "707/707 [==============================] - 626s 885ms/step - loss: 0.4680 - dense_1_loss: 0.6853 - dense_2_loss: 0.3003 - dense_3_loss: 0.2011 - dense_1_acc: 0.8701 - dense_2_acc: 0.9345 - dense_3_acc: 0.9537 - val_loss: 0.1259 - val_dense_1_loss: 0.2074 - val_dense_2_loss: 0.0588 - val_dense_3_loss: 0.0550 - val_dense_1_acc: 0.9508 - val_dense_2_acc: 0.9871 - val_dense_3_acc: 0.9862\n",
      "Epoch 28/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4627 - dense_1_loss: 0.6756 - dense_2_loss: 0.2989 - dense_3_loss: 0.2007 - dense_1_acc: 0.8720 - dense_2_acc: 0.9340 - dense_3_acc: 0.9544 - val_loss: 0.1202 - val_dense_1_loss: 0.1859 - val_dense_2_loss: 0.0553 - val_dense_3_loss: 0.0506 - val_dense_1_acc: 0.9528 - val_dense_2_acc: 0.9864 - val_dense_3_acc: 0.9865\n",
      "Epoch 29/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.4584 - dense_1_loss: 0.6684 - dense_2_loss: 0.2981 - dense_3_loss: 0.1986 - dense_1_acc: 0.8743 - dense_2_acc: 0.9339 - dense_3_acc: 0.9544 - val_loss: 0.1275 - val_dense_1_loss: 0.1902 - val_dense_2_loss: 0.0508 - val_dense_3_loss: 0.0499 - val_dense_1_acc: 0.9542 - val_dense_2_acc: 0.9881 - val_dense_3_acc: 0.9879\n",
      "Epoch 30/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4574 - dense_1_loss: 0.6682 - dense_2_loss: 0.2951 - dense_3_loss: 0.1981 - dense_1_acc: 0.8745 - dense_2_acc: 0.9352 - dense_3_acc: 0.9549 - val_loss: 0.1699 - val_dense_1_loss: 0.2235 - val_dense_2_loss: 0.0612 - val_dense_3_loss: 0.0564 - val_dense_1_acc: 0.9491 - val_dense_2_acc: 0.9851 - val_dense_3_acc: 0.9871\n",
      "Epoch 31/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.4521 - dense_1_loss: 0.6597 - dense_2_loss: 0.2929 - dense_3_loss: 0.1963 - dense_1_acc: 0.8752 - dense_2_acc: 0.9358 - dense_3_acc: 0.9548 - val_loss: 0.1426 - val_dense_1_loss: 0.2090 - val_dense_2_loss: 0.0621 - val_dense_3_loss: 0.0598 - val_dense_1_acc: 0.9501 - val_dense_2_acc: 0.9864 - val_dense_3_acc: 0.9858\n",
      "Epoch 32/80\n",
      "707/707 [==============================] - 635s 899ms/step - loss: 0.4477 - dense_1_loss: 0.6526 - dense_2_loss: 0.2920 - dense_3_loss: 0.1937 - dense_1_acc: 0.8769 - dense_2_acc: 0.9357 - dense_3_acc: 0.9556 - val_loss: 0.1120 - val_dense_1_loss: 0.2239 - val_dense_2_loss: 0.0633 - val_dense_3_loss: 0.0622 - val_dense_1_acc: 0.9530 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9862\n",
      "Epoch 33/80\n",
      "707/707 [==============================] - 628s 888ms/step - loss: 0.4449 - dense_1_loss: 0.6492 - dense_2_loss: 0.2880 - dense_3_loss: 0.1929 - dense_1_acc: 0.8778 - dense_2_acc: 0.9365 - dense_3_acc: 0.9556 - val_loss: 0.1663 - val_dense_1_loss: 0.1945 - val_dense_2_loss: 0.0554 - val_dense_3_loss: 0.0502 - val_dense_1_acc: 0.9535 - val_dense_2_acc: 0.9870 - val_dense_3_acc: 0.9883\n",
      "Epoch 34/80\n",
      "707/707 [==============================] - 634s 897ms/step - loss: 0.4395 - dense_1_loss: 0.6402 - dense_2_loss: 0.2847 - dense_3_loss: 0.1930 - dense_1_acc: 0.8793 - dense_2_acc: 0.9385 - dense_3_acc: 0.9570 - val_loss: 0.1788 - val_dense_1_loss: 0.2153 - val_dense_2_loss: 0.0604 - val_dense_3_loss: 0.0568 - val_dense_1_acc: 0.9535 - val_dense_2_acc: 0.9872 - val_dense_3_acc: 0.9876\n",
      "Epoch 35/80\n",
      "707/707 [==============================] - 636s 899ms/step - loss: 0.4358 - dense_1_loss: 0.6333 - dense_2_loss: 0.2849 - dense_3_loss: 0.1917 - dense_1_acc: 0.8805 - dense_2_acc: 0.9382 - dense_3_acc: 0.9569 - val_loss: 0.0961 - val_dense_1_loss: 0.1794 - val_dense_2_loss: 0.0550 - val_dense_3_loss: 0.0492 - val_dense_1_acc: 0.9541 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9873\n",
      "Epoch 36/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.4347 - dense_1_loss: 0.6324 - dense_2_loss: 0.2828 - dense_3_loss: 0.1911 - dense_1_acc: 0.8816 - dense_2_acc: 0.9393 - dense_3_acc: 0.9571 - val_loss: 0.1949 - val_dense_1_loss: 0.2068 - val_dense_2_loss: 0.0586 - val_dense_3_loss: 0.0597 - val_dense_1_acc: 0.9528 - val_dense_2_acc: 0.9857 - val_dense_3_acc: 0.9855\n",
      "Epoch 37/80\n",
      "707/707 [==============================] - 628s 888ms/step - loss: 0.4294 - dense_1_loss: 0.6239 - dense_2_loss: 0.2814 - dense_3_loss: 0.1884 - dense_1_acc: 0.8837 - dense_2_acc: 0.9392 - dense_3_acc: 0.9577 - val_loss: 0.0980 - val_dense_1_loss: 0.1931 - val_dense_2_loss: 0.0507 - val_dense_3_loss: 0.0514 - val_dense_1_acc: 0.9519 - val_dense_2_acc: 0.9885 - val_dense_3_acc: 0.9872\n",
      "Epoch 38/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4284 - dense_1_loss: 0.6226 - dense_2_loss: 0.2797 - dense_3_loss: 0.1885 - dense_1_acc: 0.8820 - dense_2_acc: 0.9388 - dense_3_acc: 0.9576 - val_loss: 0.1553 - val_dense_1_loss: 0.2212 - val_dense_2_loss: 0.0610 - val_dense_3_loss: 0.0605 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9866 - val_dense_3_acc: 0.9858\n",
      "Epoch 39/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.4243 - dense_1_loss: 0.6157 - dense_2_loss: 0.2788 - dense_3_loss: 0.1870 - dense_1_acc: 0.8842 - dense_2_acc: 0.9395 - dense_3_acc: 0.9588 - val_loss: 0.1120 - val_dense_1_loss: 0.1932 - val_dense_2_loss: 0.0529 - val_dense_3_loss: 0.0486 - val_dense_1_acc: 0.9543 - val_dense_2_acc: 0.9878 - val_dense_3_acc: 0.9888\n",
      "Epoch 40/80\n",
      "707/707 [==============================] - 626s 885ms/step - loss: 0.4193 - dense_1_loss: 0.6077 - dense_2_loss: 0.2762 - dense_3_loss: 0.1858 - dense_1_acc: 0.8853 - dense_2_acc: 0.9401 - dense_3_acc: 0.9588 - val_loss: 0.1210 - val_dense_1_loss: 0.2099 - val_dense_2_loss: 0.0592 - val_dense_3_loss: 0.0554 - val_dense_1_acc: 0.9522 - val_dense_2_acc: 0.9880 - val_dense_3_acc: 0.9873\n",
      "Epoch 41/80\n",
      "707/707 [==============================] - 633s 895ms/step - loss: 0.4195 - dense_1_loss: 0.6089 - dense_2_loss: 0.2750 - dense_3_loss: 0.1851 - dense_1_acc: 0.8851 - dense_2_acc: 0.9406 - dense_3_acc: 0.9590 - val_loss: 0.1494 - val_dense_1_loss: 0.1870 - val_dense_2_loss: 0.0531 - val_dense_3_loss: 0.0512 - val_dense_1_acc: 0.9539 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9875\n",
      "Epoch 42/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.4128 - dense_1_loss: 0.5976 - dense_2_loss: 0.2730 - dense_3_loss: 0.1832 - dense_1_acc: 0.8872 - dense_2_acc: 0.9414 - dense_3_acc: 0.9595 - val_loss: 0.1065 - val_dense_1_loss: 0.1924 - val_dense_2_loss: 0.0548 - val_dense_3_loss: 0.0459 - val_dense_1_acc: 0.9542 - val_dense_2_acc: 0.9872 - val_dense_3_acc: 0.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4113 - dense_1_loss: 0.5954 - dense_2_loss: 0.2717 - dense_3_loss: 0.1825 - dense_1_acc: 0.8878 - dense_2_acc: 0.9413 - dense_3_acc: 0.9597 - val_loss: 0.1427 - val_dense_1_loss: 0.2261 - val_dense_2_loss: 0.0635 - val_dense_3_loss: 0.0600 - val_dense_1_acc: 0.9520 - val_dense_2_acc: 0.9876 - val_dense_3_acc: 0.9877\n",
      "Epoch 44/80\n",
      "707/707 [==============================] - 636s 900ms/step - loss: 0.4079 - dense_1_loss: 0.5894 - dense_2_loss: 0.2716 - dense_3_loss: 0.1813 - dense_1_acc: 0.8892 - dense_2_acc: 0.9413 - dense_3_acc: 0.9596 - val_loss: 0.1377 - val_dense_1_loss: 0.2384 - val_dense_2_loss: 0.0636 - val_dense_3_loss: 0.0626 - val_dense_1_acc: 0.9540 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9875\n",
      "Epoch 45/80\n",
      "707/707 [==============================] - 632s 895ms/step - loss: 0.4043 - dense_1_loss: 0.5839 - dense_2_loss: 0.2690 - dense_3_loss: 0.1803 - dense_1_acc: 0.8910 - dense_2_acc: 0.9422 - dense_3_acc: 0.9606 - val_loss: 0.1251 - val_dense_1_loss: 0.1929 - val_dense_2_loss: 0.0525 - val_dense_3_loss: 0.0516 - val_dense_1_acc: 0.9536 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9863\n",
      "Epoch 46/80\n",
      "707/707 [==============================] - 626s 886ms/step - loss: 0.4039 - dense_1_loss: 0.5847 - dense_2_loss: 0.2667 - dense_3_loss: 0.1796 - dense_1_acc: 0.8904 - dense_2_acc: 0.9433 - dense_3_acc: 0.9603 - val_loss: 0.1319 - val_dense_1_loss: 0.1819 - val_dense_2_loss: 0.0551 - val_dense_3_loss: 0.0503 - val_dense_1_acc: 0.9550 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9885\n",
      "Epoch 47/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.3991 - dense_1_loss: 0.5762 - dense_2_loss: 0.2662 - dense_3_loss: 0.1776 - dense_1_acc: 0.8924 - dense_2_acc: 0.9429 - dense_3_acc: 0.9611 - val_loss: 0.1437 - val_dense_1_loss: 0.2119 - val_dense_2_loss: 0.0587 - val_dense_3_loss: 0.0570 - val_dense_1_acc: 0.9534 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9874\n",
      "Epoch 48/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3981 - dense_1_loss: 0.5752 - dense_2_loss: 0.2639 - dense_3_loss: 0.1781 - dense_1_acc: 0.8927 - dense_2_acc: 0.9435 - dense_3_acc: 0.9606 - val_loss: 0.1713 - val_dense_1_loss: 0.2246 - val_dense_2_loss: 0.0614 - val_dense_3_loss: 0.0589 - val_dense_1_acc: 0.9560 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9876\n",
      "Epoch 49/80\n",
      "707/707 [==============================] - 635s 898ms/step - loss: 0.3981 - dense_1_loss: 0.5744 - dense_2_loss: 0.2668 - dense_3_loss: 0.1770 - dense_1_acc: 0.8920 - dense_2_acc: 0.9434 - dense_3_acc: 0.9615 - val_loss: 0.0930 - val_dense_1_loss: 0.1957 - val_dense_2_loss: 0.0548 - val_dense_3_loss: 0.0491 - val_dense_1_acc: 0.9487 - val_dense_2_acc: 0.9866 - val_dense_3_acc: 0.9873\n",
      "Epoch 50/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3942 - dense_1_loss: 0.5684 - dense_2_loss: 0.2643 - dense_3_loss: 0.1755 - dense_1_acc: 0.8933 - dense_2_acc: 0.9431 - dense_3_acc: 0.9615 - val_loss: 0.1211 - val_dense_1_loss: 0.2127 - val_dense_2_loss: 0.0560 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9550 - val_dense_2_acc: 0.9879 - val_dense_3_acc: 0.9875\n",
      "Epoch 51/80\n",
      "402/707 [================>.............] - ETA: 4:22 - loss: 0.3914 - dense_1_loss: 0.5652 - dense_2_loss: 0.2605 - dense_3_loss: 0.1746 - dense_1_acc: 0.8935 - dense_2_acc: 0.9444 - dense_3_acc: 0.9618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 629s 890ms/step - loss: 0.3756 - dense_1_loss: 0.5384 - dense_2_loss: 0.2550 - dense_3_loss: 0.1708 - dense_1_acc: 0.9004 - dense_2_acc: 0.9458 - dense_3_acc: 0.9634 - val_loss: 0.1801 - val_dense_1_loss: 0.2350 - val_dense_2_loss: 0.0610 - val_dense_3_loss: 0.0620 - val_dense_1_acc: 0.9536 - val_dense_2_acc: 0.9886 - val_dense_3_acc: 0.9877\n",
      "Epoch 59/80\n",
      "707/707 [==============================] - 630s 891ms/step - loss: 0.3715 - dense_1_loss: 0.5336 - dense_2_loss: 0.2515 - dense_3_loss: 0.1672 - dense_1_acc: 0.9017 - dense_2_acc: 0.9481 - dense_3_acc: 0.9645 - val_loss: 0.1308 - val_dense_1_loss: 0.2668 - val_dense_2_loss: 0.0690 - val_dense_3_loss: 0.0646 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9880 - val_dense_3_acc: 0.9874\n",
      "Epoch 60/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3667 - dense_1_loss: 0.5246 - dense_2_loss: 0.2501 - dense_3_loss: 0.1674 - dense_1_acc: 0.9033 - dense_2_acc: 0.9484 - dense_3_acc: 0.9644 - val_loss: 0.1100 - val_dense_1_loss: 0.2216 - val_dense_2_loss: 0.0566 - val_dense_3_loss: 0.0539 - val_dense_1_acc: 0.9526 - val_dense_2_acc: 0.9872 - val_dense_3_acc: 0.9880\n",
      "Epoch 61/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3699 - dense_1_loss: 0.5307 - dense_2_loss: 0.2510 - dense_3_loss: 0.1673 - dense_1_acc: 0.9020 - dense_2_acc: 0.9482 - dense_3_acc: 0.9642 - val_loss: 0.1968 - val_dense_1_loss: 0.2404 - val_dense_2_loss: 0.0672 - val_dense_3_loss: 0.0613 - val_dense_1_acc: 0.9533 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9876\n",
      "Epoch 62/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3699 - dense_1_loss: 0.5307 - dense_2_loss: 0.2510 - dense_3_loss: 0.1673 - dense_1_acc: 0.9020 - dense_2_acc: 0.9482 - dense_3_acc: 0.9642 - val_loss: 0.1968 - val_dense_1_loss: 0.2404 - val_dense_2_loss: 0.0672 - val_dense_3_loss: 0.0613 - val_dense_1_acc: 0.9533 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9876\n",
      "707/707 [==============================] - 628s 888ms/step - loss: 0.3694 - dense_1_loss: 0.5293 - dense_2_loss: 0.2513 - dense_3_loss: 0.1675 - dense_1_acc: 0.9020 - dense_2_acc: 0.9482 - dense_3_acc: 0.9641 - val_loss: 0.1480 - val_dense_1_loss: 0.2323 - val_dense_2_loss: 0.0645 - val_dense_3_loss: 0.0579 - val_dense_1_acc: 0.9543 - val_dense_2_acc: 0.9879 - val_dense_3_acc: 0.9880\n",
      "Epoch 63/80\n",
      "707/707 [==============================] - 627s 886ms/step - loss: 0.3637 - dense_1_loss: 0.5193 - dense_2_loss: 0.2500 - dense_3_loss: 0.1661 - dense_1_acc: 0.9052 - dense_2_acc: 0.9478 - dense_3_acc: 0.9646 - val_loss: 0.1192 - val_dense_1_loss: 0.2141 - val_dense_2_loss: 0.0560 - val_dense_3_loss: 0.0520 - val_dense_1_acc: 0.9537 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9872\n",
      "Epoch 64/80\n",
      "707/707 [==============================] - 637s 901ms/step - loss: 0.3615 - dense_1_loss: 0.5159 - dense_2_loss: 0.2485 - dense_3_loss: 0.1654 - dense_1_acc: 0.9054 - dense_2_acc: 0.9490 - dense_3_acc: 0.9658 - val_loss: 0.1759 - val_dense_1_loss: 0.2354 - val_dense_2_loss: 0.0629 - val_dense_3_loss: 0.0549 - val_dense_1_acc: 0.9544 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9885\n",
      "Epoch 65/80\n",
      "707/707 [==============================] - 627s 886ms/step - loss: 0.3592 - dense_1_loss: 0.5133 - dense_2_loss: 0.2461 - dense_3_loss: 0.1642 - dense_1_acc: 0.9050 - dense_2_acc: 0.9495 - dense_3_acc: 0.9658 - val_loss: 0.1860 - val_dense_1_loss: 0.2501 - val_dense_2_loss: 0.0636 - val_dense_3_loss: 0.0603 - val_dense_1_acc: 0.9549 - val_dense_2_acc: 0.9881 - val_dense_3_acc: 0.9877\n",
      "Epoch 66/80\n",
      "707/707 [==============================] - 627s 887ms/step - loss: 0.3619 - dense_1_loss: 0.5190 - dense_2_loss: 0.2464 - dense_3_loss: 0.1632 - dense_1_acc: 0.9040 - dense_2_acc: 0.9497 - dense_3_acc: 0.9657 - val_loss: 0.1551 - val_dense_1_loss: 0.2636 - val_dense_2_loss: 0.0698 - val_dense_3_loss: 0.0632 - val_dense_1_acc: 0.9530 - val_dense_2_acc: 0.9876 - val_dense_3_acc: 0.9871\n",
      "Epoch 67/80\n",
      "707/707 [==============================] - 627s 886ms/step - loss: 0.3565 - dense_1_loss: 0.5088 - dense_2_loss: 0.2450 - dense_3_loss: 0.1632 - dense_1_acc: 0.9060 - dense_2_acc: 0.9499 - dense_3_acc: 0.9654 - val_loss: 0.0857 - val_dense_1_loss: 0.2219 - val_dense_2_loss: 0.0588 - val_dense_3_loss: 0.0537 - val_dense_1_acc: 0.9547 - val_dense_2_acc: 0.9875 - val_dense_3_acc: 0.9876\n",
      "Epoch 68/80\n",
      "123/707 [====>.........................] - ETA: 8:21 - loss: 0.3508 - dense_1_loss: 0.4981 - dense_2_loss: 0.2418 - dense_3_loss: 0.1655 - dense_1_acc: 0.9116 - dense_2_acc: 0.9523 - dense_3_acc: 0.9660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 635s 898ms/step - loss: 0.3355 - dense_1_loss: 0.4756 - dense_2_loss: 0.2348 - dense_3_loss: 0.1561 - dense_1_acc: 0.9135 - dense_2_acc: 0.9531 - dense_3_acc: 0.9682 - val_loss: 0.1646 - val_dense_1_loss: 0.2384 - val_dense_2_loss: 0.0665 - val_dense_3_loss: 0.0581 - val_dense_1_acc: 0.9559 - val_dense_2_acc: 0.9874 - val_dense_3_acc: 0.9880\n"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=batch_size,size=size,clahe=True,alpha=0.1)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=batch_size,size=size,clahe=True,alpha=0.1)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.5,0.25,0.25])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=80, callbacks=[checkpoint], workers=64, use_multiprocessing=True)\n",
    "model.save(\"multiXception4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 19s 237ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16458970308303833,\n",
       " 0.23835662007331848,\n",
       " 0.06650356948375702,\n",
       " 0.0581028126180172,\n",
       " 0.9558852910995483,\n",
       " 0.9874029159545898,\n",
       " 0.9880003929138184]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
