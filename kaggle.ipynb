{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from efficientnet.keras import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(120, 120)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def upper(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True,clahe=False):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    if clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "    img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3,clahe=True):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "        self.clahe=clahe\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training,clahe=self.clahe))\n",
    "         \n",
    "        \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            imgs = [randomErase(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiBased():\n",
    "    model =  Xception(weights=\"imagenet\", include_top=False,input_shape=(*size,3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Dense(1024, activation=\"relu\")(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236),y,train_size=0.9,random_state=8000)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-xce-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 59, 59, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 59, 59, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 59, 59, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 57, 57, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 57, 57, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 57, 57, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 57, 57, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 57, 57, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 57, 57, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 29, 29, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 29, 29, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 29, 29, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 29, 29, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 29, 29, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 29, 29, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 29, 29, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 29, 29, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 256)  32768       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 15, 15, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 15, 15, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 15, 15, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 15, 15, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 15, 15, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 15, 15, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 728)    186368      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 728)    2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 1024)   745472      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 168)          344232      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           22539       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 7)            14343       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,242,594\n",
      "Trainable params: 21,188,066\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "706/707 [============================>.] - ETA: 0s - loss: 2.1795 - dense_4_loss: 3.2739 - dense_5_loss: 1.3617 - dense_6_loss: 0.8086 - dense_4_acc: 0.4129 - dense_5_acc: 0.6493 - dense_6_acc: 0.7766\n",
      "707/707 [==============================] - 672s 951ms/step - loss: 2.1790 - dense_4_loss: 3.2731 - dense_5_loss: 1.3614 - dense_6_loss: 0.8085 - dense_4_acc: 0.4130 - dense_5_acc: 0.6494 - dense_6_acc: 0.7766 - val_loss: 0.3586 - val_dense_4_loss: 0.5408 - val_dense_5_loss: 0.2348 - val_dense_6_loss: 0.1754 - val_dense_4_acc: 0.8741 - val_dense_5_acc: 0.9631 - val_dense_6_acc: 0.9597\n",
      "Epoch 2/80\n",
      "707/707 [==============================] - 621s 878ms/step - loss: 1.6898 - dense_4_loss: 2.4689 - dense_5_loss: 1.1360 - dense_6_loss: 0.6856 - dense_4_acc: 0.5811 - dense_5_acc: 0.7119 - dense_6_acc: 0.8147 - val_loss: 0.1849 - val_dense_4_loss: 0.3481 - val_dense_5_loss: 0.1210 - val_dense_6_loss: 0.1175 - val_dense_4_acc: 0.9068 - val_dense_5_acc: 0.9701 - val_dense_6_acc: 0.9672\n",
      "Epoch 3/80\n",
      "707/707 [==============================] - 622s 880ms/step - loss: 1.5195 - dense_4_loss: 2.1842 - dense_5_loss: 1.0590 - dense_6_loss: 0.6506 - dense_4_acc: 0.6028 - dense_5_acc: 0.7231 - dense_6_acc: 0.8211 - val_loss: 0.1921 - val_dense_4_loss: 0.3302 - val_dense_5_loss: 0.1486 - val_dense_6_loss: 0.1330 - val_dense_4_acc: 0.9236 - val_dense_5_acc: 0.9757 - val_dense_6_acc: 0.9750\n",
      "Epoch 4/80\n",
      "707/707 [==============================] - 622s 880ms/step - loss: 1.4109 - dense_4_loss: 2.0095 - dense_5_loss: 1.0007 - dense_6_loss: 0.6239 - dense_4_acc: 0.6164 - dense_5_acc: 0.7358 - dense_6_acc: 0.8286 - val_loss: 0.1863 - val_dense_4_loss: 0.2623 - val_dense_5_loss: 0.1362 - val_dense_6_loss: 0.0945 - val_dense_4_acc: 0.9300 - val_dense_5_acc: 0.9672 - val_dense_6_acc: 0.9744\n",
      "Epoch 5/80\n",
      "707/707 [==============================] - 623s 881ms/step - loss: 1.3341 - dense_4_loss: 1.8879 - dense_5_loss: 0.9544 - dense_6_loss: 0.6060 - dense_4_acc: 0.6273 - dense_5_acc: 0.7460 - dense_6_acc: 0.8337 - val_loss: 0.2318 - val_dense_4_loss: 0.2487 - val_dense_5_loss: 0.0818 - val_dense_6_loss: 0.0796 - val_dense_4_acc: 0.9343 - val_dense_5_acc: 0.9807 - val_dense_6_acc: 0.9760\n",
      "Epoch 6/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 1.2735 - dense_4_loss: 1.7933 - dense_5_loss: 0.9155 - dense_6_loss: 0.5920 - dense_4_acc: 0.6365 - dense_5_acc: 0.7572 - dense_6_acc: 0.8381 - val_loss: 0.1841 - val_dense_4_loss: 0.2613 - val_dense_5_loss: 0.0919 - val_dense_6_loss: 0.0969 - val_dense_4_acc: 0.9307 - val_dense_5_acc: 0.9796 - val_dense_6_acc: 0.9767\n",
      "Epoch 7/80\n",
      " 84/707 [==>...........................] - ETA: 8:51 - loss: 1.2651 - dense_4_loss: 1.7861 - dense_5_loss: 0.9067 - dense_6_loss: 0.5817 - dense_4_acc: 0.6354 - dense_5_acc: 0.7552 - dense_6_acc: 0.8376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 623s 882ms/step - loss: 1.1182 - dense_4_loss: 1.5522 - dense_5_loss: 0.8220 - dense_6_loss: 0.5461 - dense_4_acc: 0.6648 - dense_5_acc: 0.7858 - dense_6_acc: 0.8540 - val_loss: 0.1451 - val_dense_4_loss: 0.2038 - val_dense_5_loss: 0.0650 - val_dense_6_loss: 0.0620 - val_dense_4_acc: 0.9466 - val_dense_5_acc: 0.9853 - val_dense_6_acc: 0.9827\n",
      "Epoch 12/80\n",
      "707/707 [==============================] - 626s 885ms/step - loss: 1.0941 - dense_4_loss: 1.5131 - dense_5_loss: 0.8108 - dense_6_loss: 0.5395 - dense_4_acc: 0.6720 - dense_5_acc: 0.7916 - dense_6_acc: 0.8580 - val_loss: 0.1152 - val_dense_4_loss: 0.1966 - val_dense_5_loss: 0.0645 - val_dense_6_loss: 0.0580 - val_dense_4_acc: 0.9466 - val_dense_5_acc: 0.9841 - val_dense_6_acc: 0.9835\n",
      "Epoch 13/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 1.0739 - dense_4_loss: 1.4800 - dense_5_loss: 0.8007 - dense_6_loss: 0.5348 - dense_4_acc: 0.6774 - dense_5_acc: 0.7973 - dense_6_acc: 0.8605 - val_loss: 0.1537 - val_dense_4_loss: 0.2220 - val_dense_5_loss: 0.0665 - val_dense_6_loss: 0.0602 - val_dense_4_acc: 0.9458 - val_dense_5_acc: 0.9844 - val_dense_6_acc: 0.9833\n",
      "Epoch 14/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 1.0572 - dense_4_loss: 1.4547 - dense_5_loss: 0.7904 - dense_6_loss: 0.5287 - dense_4_acc: 0.6833 - dense_5_acc: 0.8041 - dense_6_acc: 0.8644 - val_loss: 0.1454 - val_dense_4_loss: 0.2090 - val_dense_5_loss: 0.0642 - val_dense_6_loss: 0.0604 - val_dense_4_acc: 0.9459 - val_dense_5_acc: 0.9845 - val_dense_6_acc: 0.9833\n",
      "Epoch 15/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 1.0457 - dense_4_loss: 1.4357 - dense_5_loss: 0.7858 - dense_6_loss: 0.5255 - dense_4_acc: 0.6864 - dense_5_acc: 0.8065 - dense_6_acc: 0.8646 - val_loss: 0.1343 - val_dense_4_loss: 0.2125 - val_dense_5_loss: 0.0683 - val_dense_6_loss: 0.0636 - val_dense_4_acc: 0.9470 - val_dense_5_acc: 0.9847 - val_dense_6_acc: 0.9830\n",
      "Epoch 16/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 1.0312 - dense_4_loss: 1.4123 - dense_5_loss: 0.7810 - dense_6_loss: 0.5191 - dense_4_acc: 0.6913 - dense_5_acc: 0.8111 - dense_6_acc: 0.8669 - val_loss: 0.1491 - val_dense_4_loss: 0.2015 - val_dense_5_loss: 0.0580 - val_dense_6_loss: 0.0574 - val_dense_4_acc: 0.9459 - val_dense_5_acc: 0.9865 - val_dense_6_acc: 0.9839\n",
      "Epoch 17/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 1.0200 - dense_4_loss: 1.3963 - dense_5_loss: 0.7719 - dense_6_loss: 0.5154 - dense_4_acc: 0.6933 - dense_5_acc: 0.8132 - dense_6_acc: 0.8709 - val_loss: 0.1422 - val_dense_4_loss: 0.1922 - val_dense_5_loss: 0.0554 - val_dense_6_loss: 0.0549 - val_dense_4_acc: 0.9524 - val_dense_5_acc: 0.9868 - val_dense_6_acc: 0.9851\n",
      "Epoch 18/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 1.0077 - dense_4_loss: 1.3745 - dense_5_loss: 0.7686 - dense_6_loss: 0.5132 - dense_4_acc: 0.6995 - dense_5_acc: 0.8181 - dense_6_acc: 0.8726 - val_loss: 0.1902 - val_dense_4_loss: 0.1948 - val_dense_5_loss: 0.0725 - val_dense_6_loss: 0.0656 - val_dense_4_acc: 0.9510 - val_dense_5_acc: 0.9865 - val_dense_6_acc: 0.9829\n",
      "Epoch 19/80\n",
      "707/707 [==============================] - 623s 882ms/step - loss: 0.9978 - dense_4_loss: 1.3591 - dense_5_loss: 0.7641 - dense_6_loss: 0.5091 - dense_4_acc: 0.7028 - dense_5_acc: 0.8219 - dense_6_acc: 0.8750 - val_loss: 0.1049 - val_dense_4_loss: 0.1894 - val_dense_5_loss: 0.0615 - val_dense_6_loss: 0.0580 - val_dense_4_acc: 0.9506 - val_dense_5_acc: 0.9855 - val_dense_6_acc: 0.9849\n",
      "Epoch 20/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9878 - dense_4_loss: 1.3441 - dense_5_loss: 0.7573 - dense_6_loss: 0.5057 - dense_4_acc: 0.7071 - dense_5_acc: 0.8275 - dense_6_acc: 0.8788 - val_loss: 0.1256 - val_dense_4_loss: 0.1979 - val_dense_5_loss: 0.0610 - val_dense_6_loss: 0.0567 - val_dense_4_acc: 0.9484 - val_dense_5_acc: 0.9857 - val_dense_6_acc: 0.9843\n",
      "Epoch 21/80\n",
      "707/707 [==============================] - 625s 883ms/step - loss: 0.9812 - dense_4_loss: 1.3337 - dense_5_loss: 0.7537 - dense_6_loss: 0.5037 - dense_4_acc: 0.7084 - dense_5_acc: 0.8310 - dense_6_acc: 0.8798 - val_loss: 0.1112 - val_dense_4_loss: 0.1872 - val_dense_5_loss: 0.0563 - val_dense_6_loss: 0.0559 - val_dense_4_acc: 0.9502 - val_dense_5_acc: 0.9877 - val_dense_6_acc: 0.9868\n",
      "Epoch 22/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9705 - dense_4_loss: 1.3160 - dense_5_loss: 0.7507 - dense_6_loss: 0.4993 - dense_4_acc: 0.7110 - dense_5_acc: 0.8327 - dense_6_acc: 0.8824 - val_loss: 0.1186 - val_dense_4_loss: 0.1892 - val_dense_5_loss: 0.0555 - val_dense_6_loss: 0.0540 - val_dense_4_acc: 0.9511 - val_dense_5_acc: 0.9872 - val_dense_6_acc: 0.9853\n",
      "Epoch 23/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9661 - dense_4_loss: 1.3086 - dense_5_loss: 0.7476 - dense_6_loss: 0.4995 - dense_4_acc: 0.7137 - dense_5_acc: 0.8350 - dense_6_acc: 0.8844 - val_loss: 0.1293 - val_dense_4_loss: 0.2064 - val_dense_5_loss: 0.0650 - val_dense_6_loss: 0.0637 - val_dense_4_acc: 0.9491 - val_dense_5_acc: 0.9847 - val_dense_6_acc: 0.9821\n",
      "Epoch 24/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9575 - dense_4_loss: 1.2945 - dense_5_loss: 0.7447 - dense_6_loss: 0.4963 - dense_4_acc: 0.7176 - dense_5_acc: 0.8388 - dense_6_acc: 0.8859 - val_loss: 0.1220 - val_dense_4_loss: 0.1899 - val_dense_5_loss: 0.0566 - val_dense_6_loss: 0.0542 - val_dense_4_acc: 0.9491 - val_dense_5_acc: 0.9863 - val_dense_6_acc: 0.9855\n",
      "Epoch 25/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9502 - dense_4_loss: 1.2832 - dense_5_loss: 0.7398 - dense_6_loss: 0.4944 - dense_4_acc: 0.7211 - dense_5_acc: 0.8418 - dense_6_acc: 0.8876 - val_loss: 0.1193 - val_dense_4_loss: 0.2159 - val_dense_5_loss: 0.0577 - val_dense_6_loss: 0.0596 - val_dense_4_acc: 0.9465 - val_dense_5_acc: 0.9865 - val_dense_6_acc: 0.9838\n",
      "Epoch 26/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 0.9371 - dense_4_loss: 1.2619 - dense_5_loss: 0.7343 - dense_6_loss: 0.4905 - dense_4_acc: 0.7253 - dense_5_acc: 0.8436 - dense_6_acc: 0.8882 - val_loss: 0.1206 - val_dense_4_loss: 0.1904 - val_dense_5_loss: 0.0524 - val_dense_6_loss: 0.0522 - val_dense_4_acc: 0.9510 - val_dense_5_acc: 0.9874 - val_dense_6_acc: 0.9861\n",
      "Epoch 27/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9390 - dense_4_loss: 1.2657 - dense_5_loss: 0.7335 - dense_6_loss: 0.4910 - dense_4_acc: 0.7256 - dense_5_acc: 0.8452 - dense_6_acc: 0.8895 - val_loss: 0.0688 - val_dense_4_loss: 0.1842 - val_dense_5_loss: 0.0547 - val_dense_6_loss: 0.0536 - val_dense_4_acc: 0.9515 - val_dense_5_acc: 0.9876 - val_dense_6_acc: 0.9851\n",
      "Epoch 28/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9314 - dense_4_loss: 1.2535 - dense_5_loss: 0.7307 - dense_6_loss: 0.4881 - dense_4_acc: 0.7292 - dense_5_acc: 0.8471 - dense_6_acc: 0.8919 - val_loss: 0.1049 - val_dense_4_loss: 0.1913 - val_dense_5_loss: 0.0543 - val_dense_6_loss: 0.0626 - val_dense_4_acc: 0.9534 - val_dense_5_acc: 0.9873 - val_dense_6_acc: 0.9852\n",
      "Epoch 29/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 0.9231 - dense_4_loss: 1.2394 - dense_5_loss: 0.7270 - dense_6_loss: 0.4868 - dense_4_acc: 0.7326 - dense_5_acc: 0.8504 - dense_6_acc: 0.8940 - val_loss: 0.1205 - val_dense_4_loss: 0.1821 - val_dense_5_loss: 0.0590 - val_dense_6_loss: 0.0527 - val_dense_4_acc: 0.9529 - val_dense_5_acc: 0.9859 - val_dense_6_acc: 0.9862\n",
      "Epoch 30/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9229 - dense_4_loss: 1.2390 - dense_5_loss: 0.7270 - dense_6_loss: 0.4867 - dense_4_acc: 0.7310 - dense_5_acc: 0.8509 - dense_6_acc: 0.8930 - val_loss: 0.1035 - val_dense_4_loss: 0.2026 - val_dense_5_loss: 0.0633 - val_dense_6_loss: 0.0584 - val_dense_4_acc: 0.9509 - val_dense_5_acc: 0.9856 - val_dense_6_acc: 0.9846\n",
      "Epoch 31/80\n",
      "707/707 [==============================] - 624s 882ms/step - loss: 0.9162 - dense_4_loss: 1.2290 - dense_5_loss: 0.7250 - dense_6_loss: 0.4819 - dense_4_acc: 0.7359 - dense_5_acc: 0.8533 - dense_6_acc: 0.8973 - val_loss: 0.0859 - val_dense_4_loss: 0.1853 - val_dense_5_loss: 0.0591 - val_dense_6_loss: 0.0538 - val_dense_4_acc: 0.9539 - val_dense_5_acc: 0.9869 - val_dense_6_acc: 0.9869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.9049 - dense_4_loss: 1.2096 - dense_5_loss: 0.7195 - dense_6_loss: 0.4809 - dense_4_acc: 0.7414 - dense_5_acc: 0.8542 - dense_6_acc: 0.8976 - val_loss: 0.0976 - val_dense_4_loss: 0.2145 - val_dense_5_loss: 0.0616 - val_dense_6_loss: 0.0626 - val_dense_4_acc: 0.9520 - val_dense_5_acc: 0.9865 - val_dense_6_acc: 0.9861\n",
      "Epoch 33/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.9030 - dense_4_loss: 1.2076 - dense_5_loss: 0.7190 - dense_6_loss: 0.4780 - dense_4_acc: 0.7416 - dense_5_acc: 0.8572 - dense_6_acc: 0.9000 - val_loss: 0.1061 - val_dense_4_loss: 0.1877 - val_dense_5_loss: 0.0548 - val_dense_6_loss: 0.0527 - val_dense_4_acc: 0.9537 - val_dense_5_acc: 0.9876 - val_dense_6_acc: 0.9864\n",
      "Epoch 34/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.8966 - dense_4_loss: 1.1964 - dense_5_loss: 0.7158 - dense_6_loss: 0.4780 - dense_4_acc: 0.7435 - dense_5_acc: 0.8588 - dense_6_acc: 0.9003 - val_loss: 0.0848 - val_dense_4_loss: 0.1897 - val_dense_5_loss: 0.0532 - val_dense_6_loss: 0.0516 - val_dense_4_acc: 0.9521 - val_dense_5_acc: 0.9879 - val_dense_6_acc: 0.9864\n",
      "Epoch 35/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.8933 - dense_4_loss: 1.1907 - dense_5_loss: 0.7142 - dense_6_loss: 0.4775 - dense_4_acc: 0.7451 - dense_5_acc: 0.8594 - dense_6_acc: 0.8999 - val_loss: 0.0846 - val_dense_4_loss: 0.1848 - val_dense_5_loss: 0.0540 - val_dense_6_loss: 0.0570 - val_dense_4_acc: 0.9508 - val_dense_5_acc: 0.9871 - val_dense_6_acc: 0.9838\n",
      "Epoch 36/80\n",
      "707/707 [==============================] - 624s 883ms/step - loss: 0.8905 - dense_4_loss: 1.1880 - dense_5_loss: 0.7114 - dense_6_loss: 0.4744 - dense_4_acc: 0.7467 - dense_5_acc: 0.8609 - dense_6_acc: 0.9023 - val_loss: 0.0574 - val_dense_4_loss: 0.1735 - val_dense_5_loss: 0.0509 - val_dense_6_loss: 0.0480 - val_dense_4_acc: 0.9565 - val_dense_5_acc: 0.9886 - val_dense_6_acc: 0.9876\n",
      "Epoch 37/80\n",
      "707/707 [==============================] - 625s 884ms/step - loss: 0.8831 - dense_4_loss: 1.1746 - dense_5_loss: 0.7094 - dense_6_loss: 0.4737 - dense_4_acc: 0.7510 - dense_5_acc: 0.8626 - dense_6_acc: 0.9025 - val_loss: 0.0634 - val_dense_4_loss: 0.1951 - val_dense_5_loss: 0.0544 - val_dense_6_loss: 0.0550 - val_dense_4_acc: 0.9531 - val_dense_5_acc: 0.9877 - val_dense_6_acc: 0.9868\n",
      "Epoch 38/80\n",
      "640/707 [==========================>...] - ETA: 57s - loss: 0.8775 - dense_4_loss: 1.1667 - dense_5_loss: 0.7062 - dense_6_loss: 0.4706 - dense_4_acc: 0.7527 - dense_5_acc: 0.8645 - dense_6_acc: 0.9049"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=batch_size,size=size,clahe=True)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=batch_size,size=size,clahe=True)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.5,0.25,0.25])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=80, callbacks=[checkpoint], workers=64, use_multiprocessing=True)\n",
    "model.save(\"multiXceptionMixup.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 19s 237ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1342727541923523,\n",
       " 0.245595321059227,\n",
       " 0.05994708463549614,\n",
       " 0.05561811849474907,\n",
       " 0.9542421698570251,\n",
       " 0.9891954064369202,\n",
       " 0.9882991313934326]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
