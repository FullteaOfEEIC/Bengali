{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model , load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D, ReLU\n",
    "from keras.optimizers import Adam, Optimizer\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.applications.resnet_v2 import ResNet50V2, ResNet152V2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "from keras.engine import Layer\n",
    "#import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from efficientnet.keras import EfficientNetB0\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3,transform=None,trim=\"edge\"):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "        self.transform=transform\n",
    "        self.trim=trim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training,trim=self.trim))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            _imgs=[]\n",
    "            for img in imgs:\n",
    "                if np.random.random()<0.5:\n",
    "                    res = self.transform(image=img)\n",
    "                    img = res['image'].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "                _imgs.append(img)\n",
    "            imgs=_imgs \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            imgs = [cutout(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True,clahe=False,mergin=5,trim=\"edge\"):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    if trim==\"edge\":\n",
    "        img = img[upper(img,mergin):lower(img,mergin),lefter(img,mergin):righter(img,mergin)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def cutout(image_origin):\n",
    "    # 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
    "    image = np.copy(image_origin)\n",
    "    mask_value = image.mean()\n",
    "\n",
    "    h, w, c = image.shape\n",
    "    # マスクをかける場所のtop, leftをランダムに決める\n",
    "    # はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
    "    mask_size=h//2\n",
    "    top = np.random.randint(0 - mask_size // 2, h - mask_size)\n",
    "    left = np.random.randint(0 - mask_size // 2, w - mask_size)\n",
    "    bottom = top + mask_size\n",
    "    right = left + mask_size\n",
    "\n",
    "    # はみ出した場合の処理\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "\n",
    "    # マスク部分の画素値を平均値で埋める\n",
    "    image[top:bottom, left:right, :].fill(mask_value)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiBased():\n",
    "    model =  Xception(weights=\"imagenet\", include_top=False, input_shape=(*size,3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(rate=0.7)(x)\n",
    "    #x = Dense(1024)(x)\n",
    "    #grapheme = PReLU()(x)\n",
    "    #grapheme = Dropout(0.5)(grapheme)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    #vowel = ReLU()(x)\n",
    "    #vowel = Dropout(0.5)(vowel)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    #consonant = ReLU()(x)\n",
    "    #consonant = Dropout(0.5)(consonant)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236), y, train_size=0.9, random_state=6666)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-xce-justresize-epoch{epoch:04}.h5\")\n",
    "schedule = ReduceLROnPlateau(patience=5,verbose=1)\n",
    "tensorboard=TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=batch_size,size=size,alpha=1.0,trim=None)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=batch_size,size=size,trim=None)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.5,0.25,0.25])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=70, workers=16, use_multiprocessing=True, callbacks=[checkpoint,schedule,tensorboard])\n",
    "model.save(\"multiXception11-justresize.h5\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
