{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169#, preprocess_input\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(137,137)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def transformImg(img):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    mu = cv2.moments(img, False)\n",
    "    x, y= mu[\"m10\"]/mu[\"m00\"] , mu[\"m01\"]/mu[\"m00\"]\n",
    "    M = np.float32([[1,0,(236/2)-x],[0,1,(137/2)-y]])\n",
    "    img = cv2.warpAffine(img,M,(img.shape[1],img.shape[0]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    #img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def rotateImg(img, prob=True):\n",
    "    if prob==False or np.random.random()<0.5:\n",
    "        angle=np.random.random()*60-30\n",
    "        trans = cv2.getRotationMatrix2D((img.shape[0]/2, img.shape[1]/2), angle , 1.0)\n",
    "        img = cv2.warpAffine(img, trans, (img.shape[1],img.shape[0]))\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def shiftImg(img, prob=True):\n",
    "    if prob==False or np.random.random()<0.5:\n",
    "        x=np.random.random()*30-15\n",
    "        y=np.random.random()*30-15\n",
    "        trans = np.float32([[1,0,x],[0,1,y]])\n",
    "        img = cv2.warpAffine(img, trans, (img.shape[1],img.shape[0]))\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "        p=False\n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            if p:\n",
    "                imgs.append(np.fft.fft2(transformImg(img)))\n",
    "            else:\n",
    "                imgs.append(transformImg(img))\n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training and np.random.random()<0.8:\n",
    "            r= np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            alpha=np.random.randn(imgs.shape[0])+0.5\n",
    "            alpha[alpha>1]=1\n",
    "            alpha[alpha<0]=0\n",
    "            imgs=np.tile(alpha,(3,*size,1)).T*imgs+np.tile((1-alpha),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(alpha,(168,1)).T*grapheme+np.tile((1-alpha),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(alpha,(11,1)).T*vowel+np.tile((1-alpha),(11,1)).T*vowel2\n",
    "            consonant=np.tile(alpha,(7,1)).T*consonant+np.tile((1-alpha),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "        \n",
    "            \n",
    "        if self.training:\n",
    "            imgs = [rotateImg(img) for img in imgs]\n",
    "            imgs = [shiftImg(img) for img in imgs]\n",
    "            imgs = [randomErase(img) for img in imgs]\n",
    "            \n",
    "        if p:\n",
    "            imgs=[np.real(np.fft.ifft2(img)) for img in imgs]\n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiXceptionBased():\n",
    "    model =  Xception(weights=\"imagenet\", include_top=False)\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model\n",
    "\n",
    "def getMultiResBased():\n",
    "    model =  ResNet152V2(weights=\"imagenet\", include_top=False,input_shape=(*size,3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236),y,train_size=0.9,random_state=923)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"Res-without-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234553344/234545216 [==============================] - 102s 0us/step\n",
      "compiled\n",
      "Epoch 1/60\n",
      "2824/2825 [============================>.] - ETA: 0s - loss: 5.8807 - dense_1_loss: 2.2968 - dense_2_loss: 0.7646 - dense_3_loss: 0.5225 - dense_1_acc: 0.4902 - dense_2_acc: 0.7864 - dense_3_acc: 0.8459Epoch 1/60\n",
      "2825/2825 [==============================] - 1822s 645ms/step - loss: 5.8799 - dense_1_loss: 2.2964 - dense_2_loss: 0.7645 - dense_3_loss: 0.5225 - dense_1_acc: 0.4903 - dense_2_acc: 0.7865 - dense_3_acc: 0.8460 - val_loss: 2.5276 - val_dense_1_loss: 0.9953 - val_dense_2_loss: 0.2362 - val_dense_3_loss: 0.3910 - val_dense_1_acc: 0.7336 - val_dense_2_acc: 0.9306 - val_dense_3_acc: 0.8829\n",
      "Epoch 2/60\n",
      " 843/2825 [=======>......................] - ETA: 18:39 - loss: 4.2218 - dense_1_loss: 1.6051 - dense_2_loss: 0.6003 - dense_3_loss: 0.4113 - dense_1_acc: 0.6695 - dense_2_acc: 0.8529 - dense_3_acc: 0.8877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2825 [==============================] - 1674s 593ms/step - loss: 3.2738 - dense_1_loss: 1.2424 - dense_2_loss: 0.4702 - dense_3_loss: 0.3188 - dense_1_acc: 0.7582 - dense_2_acc: 0.8909 - dense_3_acc: 0.9172 - val_loss: 1.0146 - val_dense_1_loss: 0.2877 - val_dense_2_loss: 0.0991 - val_dense_3_loss: 0.0897 - val_dense_1_acc: 0.9183 - val_dense_2_acc: 0.9726 - val_dense_3_acc: 0.9747\n",
      "Epoch 5/60\n",
      "2825/2825 [==============================] - 1681s 595ms/step - loss: 3.1282 - dense_1_loss: 1.1861 - dense_2_loss: 0.4502 - dense_3_loss: 0.3058 - dense_1_acc: 0.7736 - dense_2_acc: 0.8961 - dense_3_acc: 0.9225 - val_loss: 1.0432 - val_dense_1_loss: 0.2847 - val_dense_2_loss: 0.0834 - val_dense_3_loss: 0.0884 - val_dense_1_acc: 0.9186 - val_dense_2_acc: 0.9779 - val_dense_3_acc: 0.9740\n",
      "Epoch 6/60\n",
      "2825/2825 [==============================] - 1677s 594ms/step - loss: 3.0160 - dense_1_loss: 1.1450 - dense_2_loss: 0.4325 - dense_3_loss: 0.2935 - dense_1_acc: 0.7834 - dense_2_acc: 0.9002 - dense_3_acc: 0.9255 - val_loss: 0.6837 - val_dense_1_loss: 0.2469 - val_dense_2_loss: 0.0751 - val_dense_3_loss: 0.0770 - val_dense_1_acc: 0.9311 - val_dense_2_acc: 0.9805 - val_dense_3_acc: 0.9783\n",
      "Epoch 7/60\n",
      " 144/2825 [>.............................] - ETA: 25:10 - loss: 3.7679 - dense_1_loss: 1.4212 - dense_2_loss: 0.5547 - dense_3_loss: 0.3709 - dense_1_acc: 0.7301 - dense_2_acc: 0.8640 - dense_3_acc: 0.9009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2825 [==============================] - 1677s 594ms/step - loss: 2.7271 - dense_1_loss: 1.0342 - dense_2_loss: 0.3919 - dense_3_loss: 0.2669 - dense_1_acc: 0.8092 - dense_2_acc: 0.9106 - dense_3_acc: 0.9339 - val_loss: 0.8779 - val_dense_1_loss: 0.2103 - val_dense_2_loss: 0.0658 - val_dense_3_loss: 0.0732 - val_dense_1_acc: 0.9395 - val_dense_2_acc: 0.9828 - val_dense_3_acc: 0.9789\n",
      "Epoch 11/60\n",
      " 487/2825 [====>.........................] - ETA: 22:02 - loss: 3.0455 - dense_1_loss: 1.1534 - dense_2_loss: 0.4442 - dense_3_loss: 0.2946 - dense_1_acc: 0.7945 - dense_2_acc: 0.8990 - dense_3_acc: 0.9277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2825 [==============================] - 1680s 595ms/step - loss: 2.5464 - dense_1_loss: 0.9653 - dense_2_loss: 0.3664 - dense_3_loss: 0.2493 - dense_1_acc: 0.8244 - dense_2_acc: 0.9175 - dense_3_acc: 0.9386 - val_loss: 0.7272 - val_dense_1_loss: 0.1993 - val_dense_2_loss: 0.0631 - val_dense_3_loss: 0.0622 - val_dense_1_acc: 0.9438 - val_dense_2_acc: 0.9821 - val_dense_3_acc: 0.9820\n",
      "Epoch 15/60\n",
      " 784/2825 [=======>......................] - ETA: 19:14 - loss: 2.6692 - dense_1_loss: 1.0101 - dense_2_loss: 0.3855 - dense_3_loss: 0.2636 - dense_1_acc: 0.8210 - dense_2_acc: 0.9151 - dense_3_acc: 0.9372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825/2825 [==============================] - 1680s 595ms/step - loss: 2.4844 - dense_1_loss: 0.9397 - dense_2_loss: 0.3601 - dense_3_loss: 0.2449 - dense_1_acc: 0.8291 - dense_2_acc: 0.9185 - dense_3_acc: 0.9407 - val_loss: 0.9350 - val_dense_1_loss: 0.1864 - val_dense_2_loss: 0.0583 - val_dense_3_loss: 0.0664 - val_dense_1_acc: 0.9474 - val_dense_2_acc: 0.9842 - val_dense_3_acc: 0.9811\n",
      "Epoch 17/60\n",
      "2825/2825 [==============================] - 1681s 595ms/step - loss: 2.4561 - dense_1_loss: 0.9297 - dense_2_loss: 0.3549 - dense_3_loss: 0.2418 - dense_1_acc: 0.8312 - dense_2_acc: 0.9190 - dense_3_acc: 0.9412 - val_loss: 0.8412 - val_dense_1_loss: 0.1786 - val_dense_2_loss: 0.0593 - val_dense_3_loss: 0.0593 - val_dense_1_acc: 0.9484 - val_dense_2_acc: 0.9844 - val_dense_3_acc: 0.9846\n",
      "Epoch 18/60\n",
      "2825/2825 [==============================] - 1680s 595ms/step - loss: 2.4211 - dense_1_loss: 0.9152 - dense_2_loss: 0.3511 - dense_3_loss: 0.2395 - dense_1_acc: 0.8343 - dense_2_acc: 0.9211 - dense_3_acc: 0.9426 - val_loss: 0.6802 - val_dense_1_loss: 0.1851 - val_dense_2_loss: 0.0560 - val_dense_3_loss: 0.0570 - val_dense_1_acc: 0.9486 - val_dense_2_acc: 0.9853 - val_dense_3_acc: 0.9846\n",
      "Epoch 19/60\n",
      "2825/2825 [==============================] - 1681s 595ms/step - loss: 2.4101 - dense_1_loss: 0.9121 - dense_2_loss: 0.3475 - dense_3_loss: 0.2384 - dense_1_acc: 0.8350 - dense_2_acc: 0.9215 - dense_3_acc: 0.9428 - val_loss: 0.8431 - val_dense_1_loss: 0.1863 - val_dense_2_loss: 0.0596 - val_dense_3_loss: 0.0600 - val_dense_1_acc: 0.9473 - val_dense_2_acc: 0.9842 - val_dense_3_acc: 0.9837\n",
      "Epoch 20/60\n",
      "2825/2825 [==============================] - 1679s 594ms/step - loss: 2.3782 - dense_1_loss: 0.8982 - dense_2_loss: 0.3450 - dense_3_loss: 0.2369 - dense_1_acc: 0.8379 - dense_2_acc: 0.9227 - dense_3_acc: 0.9426 - val_loss: 0.8770 - val_dense_1_loss: 0.1788 - val_dense_2_loss: 0.0574 - val_dense_3_loss: 0.0582 - val_dense_1_acc: 0.9479 - val_dense_2_acc: 0.9859 - val_dense_3_acc: 0.9842\n",
      "Epoch 21/60\n",
      "2825/2825 [==============================] - 1676s 593ms/step - loss: 2.3548 - dense_1_loss: 0.8905 - dense_2_loss: 0.3406 - dense_3_loss: 0.2331 - dense_1_acc: 0.8389 - dense_2_acc: 0.9235 - dense_3_acc: 0.9444 - val_loss: 0.7613 - val_dense_1_loss: 0.1754 - val_dense_2_loss: 0.0581 - val_dense_3_loss: 0.0580 - val_dense_1_acc: 0.9512 - val_dense_2_acc: 0.9850 - val_dense_3_acc: 0.9833\n",
      "Epoch 22/60\n",
      "2825/2825 [==============================] - 1677s 594ms/step - loss: 2.3348 - dense_1_loss: 0.8828 - dense_2_loss: 0.3384 - dense_3_loss: 0.2307 - dense_1_acc: 0.8399 - dense_2_acc: 0.9235 - dense_3_acc: 0.9456 - val_loss: 0.6015 - val_dense_1_loss: 0.1853 - val_dense_2_loss: 0.0539 - val_dense_3_loss: 0.0601 - val_dense_1_acc: 0.9487 - val_dense_2_acc: 0.9865 - val_dense_3_acc: 0.9834\n",
      "Epoch 23/60\n",
      "2825/2825 [==============================] - 1679s 594ms/step - loss: 2.3161 - dense_1_loss: 0.8754 - dense_2_loss: 0.3352 - dense_3_loss: 0.2301 - dense_1_acc: 0.8414 - dense_2_acc: 0.9248 - dense_3_acc: 0.9452 - val_loss: 0.5821 - val_dense_1_loss: 0.1741 - val_dense_2_loss: 0.0511 - val_dense_3_loss: 0.0535 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9856\n",
      "Epoch 24/60\n",
      "2825/2825 [==============================] - 1681s 595ms/step - loss: 2.2935 - dense_1_loss: 0.8671 - dense_2_loss: 0.3309 - dense_3_loss: 0.2282 - dense_1_acc: 0.8433 - dense_2_acc: 0.9259 - dense_3_acc: 0.9451 - val_loss: 0.6368 - val_dense_1_loss: 0.1745 - val_dense_2_loss: 0.0534 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9513 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9866\n",
      "Epoch 25/60\n",
      "2825/2825 [==============================] - 1676s 593ms/step - loss: 2.2820 - dense_1_loss: 0.8623 - dense_2_loss: 0.3307 - dense_3_loss: 0.2267 - dense_1_acc: 0.8435 - dense_2_acc: 0.9258 - dense_3_acc: 0.9459 - val_loss: 0.7183 - val_dense_1_loss: 0.1823 - val_dense_2_loss: 0.0547 - val_dense_3_loss: 0.0596 - val_dense_1_acc: 0.9505 - val_dense_2_acc: 0.9860 - val_dense_3_acc: 0.9843\n",
      "Epoch 26/60\n",
      "2825/2825 [==============================] - 1680s 595ms/step - loss: 2.2510 - dense_1_loss: 0.8488 - dense_2_loss: 0.3282 - dense_3_loss: 0.2252 - dense_1_acc: 0.8467 - dense_2_acc: 0.9264 - dense_3_acc: 0.9462 - val_loss: 0.9643 - val_dense_1_loss: 0.1796 - val_dense_2_loss: 0.0539 - val_dense_3_loss: 0.0519 - val_dense_1_acc: 0.9507 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9869\n",
      "Epoch 27/60\n",
      "2825/2825 [==============================] - 1679s 594ms/step - loss: 2.2375 - dense_1_loss: 0.8444 - dense_2_loss: 0.3259 - dense_3_loss: 0.2227 - dense_1_acc: 0.8478 - dense_2_acc: 0.9269 - dense_3_acc: 0.9467 - val_loss: 0.6608 - val_dense_1_loss: 0.1707 - val_dense_2_loss: 0.0487 - val_dense_3_loss: 0.0530 - val_dense_1_acc: 0.9551 - val_dense_2_acc: 0.9872 - val_dense_3_acc: 0.9861\n",
      "Epoch 28/60\n",
      "2825/2825 [==============================] - 1599s 566ms/step - loss: 2.2282 - dense_1_loss: 0.8409 - dense_2_loss: 0.3242 - dense_3_loss: 0.2223 - dense_1_acc: 0.8484 - dense_2_acc: 0.9275 - dense_3_acc: 0.9473 - val_loss: 0.8123 - val_dense_1_loss: 0.1722 - val_dense_2_loss: 0.0483 - val_dense_3_loss: 0.0536 - val_dense_1_acc: 0.9552 - val_dense_2_acc: 0.9881 - val_dense_3_acc: 0.9867\n",
      "Epoch 29/60\n",
      "2825/2825 [==============================] - 1482s 525ms/step - loss: 2.2092 - dense_1_loss: 0.8320 - dense_2_loss: 0.3225 - dense_3_loss: 0.2226 - dense_1_acc: 0.8491 - dense_2_acc: 0.9278 - dense_3_acc: 0.9465 - val_loss: 0.8647 - val_dense_1_loss: 0.1609 - val_dense_2_loss: 0.0506 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9563 - val_dense_2_acc: 0.9878 - val_dense_3_acc: 0.9868\n",
      "Epoch 30/60\n",
      "2825/2825 [==============================] - 1483s 525ms/step - loss: 2.1932 - dense_1_loss: 0.8265 - dense_2_loss: 0.3205 - dense_3_loss: 0.2198 - dense_1_acc: 0.8511 - dense_2_acc: 0.9282 - dense_3_acc: 0.9481 - val_loss: 0.6388 - val_dense_1_loss: 0.1691 - val_dense_2_loss: 0.0527 - val_dense_3_loss: 0.0540 - val_dense_1_acc: 0.9554 - val_dense_2_acc: 0.9874 - val_dense_3_acc: 0.9865\n",
      "Epoch 31/60\n",
      "2134/2825 [=====================>........] - ETA: 5:44 - loss: 2.1464 - dense_1_loss: 0.8080 - dense_2_loss: 0.3145 - dense_3_loss: 0.2159 - dense_1_acc: 0.8521 - dense_2_acc: 0.9294 - dense_3_acc: 0.9491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504/2825 [=========================>....] - ETA: 2:40 - loss: 2.1789 - dense_1_loss: 0.8207 - dense_2_loss: 0.3191 - dense_3_loss: 0.2183 - dense_1_acc: 0.8520 - dense_2_acc: 0.9288 - dense_3_acc: 0.9488"
     ]
    }
   ],
   "source": [
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=64)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=64)\n",
    "model = getMultiResBased()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[2.,1.,1.])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=60, callbacks=[early_stopping, checkpoint], workers=multiprocessing.cpu_count(), use_multiprocessing=True)\n",
    "model.save(\"multiRes-without.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
