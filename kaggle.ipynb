{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from efficientnet.keras import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.set_index(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)) for i in range(4)]\n",
    "tables = [table.to_pandas() for table in tables]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_image(img):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        img: (h, w) or (1, h, w)\n",
    "\n",
    "    Returns:\n",
    "        img: (h, w)\n",
    "    \"\"\"\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(120, 120)\n",
    "\n",
    "def calcRotate(img):\n",
    "    detector = cv2.ORB_create()\n",
    "    keypoints=detector.detect(img)\n",
    "    descriptors=detector.compute(img,keypoints)\n",
    "    angles=[]\n",
    "    weights=[]\n",
    "    for i in descriptors[0]:\n",
    "        if i.angle!=-1:\n",
    "            angles.append(i.angle)\n",
    "            weights.append(i.response)\n",
    "    if len(angles)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.average(angles,weights=weights)\n",
    "\n",
    "def upper(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=20):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=20):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def randomErase(img, prob=True):\n",
    "    # random erasing\n",
    "    # https://github.com/yu4u/cutout-random-erasing\n",
    "    p = 0.5\n",
    "    s_l = 0.02\n",
    "    s_h = 0.4\n",
    "    r_1 = 0.3\n",
    "    r_2 = 1 / 0.3\n",
    "    v_l = 0\n",
    "    v_h = 255\n",
    "    input_size=size[0]\n",
    "    if prob==False or np.random.random()<p:\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, input_size)\n",
    "            top = np.random.randint(0, input_size)\n",
    "            if left + w <= input_size and top + h <= input_size:\n",
    "                break\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "        img[top : top + h, left : left + w, :] = c\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "            \n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training))\n",
    "         \n",
    "        \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            imgs = [randomErase(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiBased():\n",
    "    model =  Xception(weights=\"imagenet\", include_top=False,input_shape=(*size,3))\n",
    "    x = model.output  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Dense(1024, activation=\"relu\")(x)\n",
    "    grapheme = Dense(168, activation=\"softmax\")(x)\n",
    "    vowel = Dense(11,activation=\"softmax\")(x)\n",
    "    consonant = Dense(7, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=model.input, outputs=[grapheme,vowel,consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236),y,train_size=0.9,random_state=8000)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping =  EarlyStopping(monitor='val_loss', min_delta=0.0, patience=20)\n",
    "checkpoint = ModelCheckpoint(filepath=\"tmp-xce-epoch{epoch:04}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 59, 59, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 59, 59, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 59, 59, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 57, 57, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 57, 57, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 57, 57, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 57, 57, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 57, 57, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 57, 57, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 57, 57, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 29, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 29, 29, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 29, 29, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 29, 29, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 29, 29, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 29, 29, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 29, 29, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 29, 29, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 29, 29, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 15, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 15, 15, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15, 15, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 15, 15, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 15, 15, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 15, 15, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 15, 15, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 15, 15, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 168)          344232      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           22539       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            14343       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,242,594\n",
      "Trainable params: 21,188,066\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "706/707 [============================>.] - ETA: 0s - loss: 2.0873 - dense_1_loss: 3.1427 - dense_2_loss: 1.2870 - dense_3_loss: 0.7768 - dense_1_acc: 0.4673 - dense_2_acc: 0.6836 - dense_3_acc: 0.7938\n",
      "\n",
      "707/707 [==============================] - 667s 944ms/step - loss: 2.0868 - dense_1_loss: 3.1420 - dense_2_loss: 1.2867 - dense_3_loss: 0.7767 - dense_1_acc: 0.4675 - dense_2_acc: 0.6837 - dense_3_acc: 0.7939 - val_loss: 0.2951 - val_dense_1_loss: 0.5345 - val_dense_2_loss: 0.2373 - val_dense_3_loss: 0.1682 - val_dense_1_acc: 0.8788 - val_dense_2_acc: 0.9519 - val_dense_3_acc: 0.9529\n",
      "Epoch 2/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 1.6628 - dense_1_loss: 2.4564 - dense_2_loss: 1.0764 - dense_3_loss: 0.6620 - dense_1_acc: 0.5948 - dense_2_acc: 0.7237 - dense_3_acc: 0.8187 - val_loss: 0.2507 - val_dense_1_loss: 0.3816 - val_dense_2_loss: 0.1947 - val_dense_3_loss: 0.1316 - val_dense_1_acc: 0.8959 - val_dense_2_acc: 0.9507 - val_dense_3_acc: 0.9631\n",
      "Epoch 3/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.4963 - dense_1_loss: 2.1753 - dense_2_loss: 1.0063 - dense_3_loss: 0.6284 - dense_1_acc: 0.6043 - dense_2_acc: 0.7289 - dense_3_acc: 0.8214 - val_loss: 0.2267 - val_dense_1_loss: 0.3408 - val_dense_2_loss: 0.1508 - val_dense_3_loss: 0.1144 - val_dense_1_acc: 0.9152 - val_dense_2_acc: 0.9717 - val_dense_3_acc: 0.9739\n",
      "Epoch 4/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.3813 - dense_1_loss: 1.9813 - dense_2_loss: 0.9563 - dense_3_loss: 0.6062 - dense_1_acc: 0.6154 - dense_2_acc: 0.7433 - dense_3_acc: 0.8280 - val_loss: 0.1385 - val_dense_1_loss: 0.2510 - val_dense_2_loss: 0.1006 - val_dense_3_loss: 0.0908 - val_dense_1_acc: 0.9328 - val_dense_2_acc: 0.9765 - val_dense_3_acc: 0.9781\n",
      "Epoch 5/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.2926 - dense_1_loss: 1.8315 - dense_2_loss: 0.9190 - dense_3_loss: 0.5883 - dense_1_acc: 0.6277 - dense_2_acc: 0.7551 - dense_3_acc: 0.8353 - val_loss: 0.1394 - val_dense_1_loss: 0.2509 - val_dense_2_loss: 0.1063 - val_dense_3_loss: 0.0956 - val_dense_1_acc: 0.9354 - val_dense_2_acc: 0.9766 - val_dense_3_acc: 0.9800\n",
      "Epoch 6/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 1.2237 - dense_1_loss: 1.7168 - dense_2_loss: 0.8884 - dense_3_loss: 0.5729 - dense_1_acc: 0.6385 - dense_2_acc: 0.7653 - dense_3_acc: 0.8419 - val_loss: 0.1526 - val_dense_1_loss: 0.2338 - val_dense_2_loss: 0.0809 - val_dense_3_loss: 0.0753 - val_dense_1_acc: 0.9364 - val_dense_2_acc: 0.9818 - val_dense_3_acc: 0.9814\n",
      "Epoch 7/80\n",
      "707/707 [==============================] - 626s 885ms/step - loss: 1.1734 - dense_1_loss: 1.6345 - dense_2_loss: 0.8611 - dense_3_loss: 0.5636 - dense_1_acc: 0.6452 - dense_2_acc: 0.7754 - dense_3_acc: 0.8451 - val_loss: 0.1341 - val_dense_1_loss: 0.2334 - val_dense_2_loss: 0.0945 - val_dense_3_loss: 0.0820 - val_dense_1_acc: 0.9395 - val_dense_2_acc: 0.9822 - val_dense_3_acc: 0.9818\n",
      "Epoch 8/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.1273 - dense_1_loss: 1.5610 - dense_2_loss: 0.8382 - dense_3_loss: 0.5490 - dense_1_acc: 0.6530 - dense_2_acc: 0.7869 - dense_3_acc: 0.8500 - val_loss: 0.1537 - val_dense_1_loss: 0.2381 - val_dense_2_loss: 0.0962 - val_dense_3_loss: 0.0760 - val_dense_1_acc: 0.9363 - val_dense_2_acc: 0.9821 - val_dense_3_acc: 0.9822\n",
      "Epoch 9/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 1.0978 - dense_1_loss: 1.5153 - dense_2_loss: 0.8187 - dense_3_loss: 0.5419 - dense_1_acc: 0.6596 - dense_2_acc: 0.7978 - dense_3_acc: 0.8523 - val_loss: 0.1260 - val_dense_1_loss: 0.2172 - val_dense_2_loss: 0.0962 - val_dense_3_loss: 0.0802 - val_dense_1_acc: 0.9418 - val_dense_2_acc: 0.9819 - val_dense_3_acc: 0.9829\n",
      "Epoch 10/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 1.0696 - dense_1_loss: 1.4710 - dense_2_loss: 0.8011 - dense_3_loss: 0.5352 - dense_1_acc: 0.6659 - dense_2_acc: 0.8069 - dense_3_acc: 0.8556 - val_loss: 0.0987 - val_dense_1_loss: 0.2037 - val_dense_2_loss: 0.0836 - val_dense_3_loss: 0.0716 - val_dense_1_acc: 0.9463 - val_dense_2_acc: 0.9844 - val_dense_3_acc: 0.9829\n",
      "Epoch 11/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.0424 - dense_1_loss: 1.4283 - dense_2_loss: 0.7849 - dense_3_loss: 0.5282 - dense_1_acc: 0.6726 - dense_2_acc: 0.8151 - dense_3_acc: 0.8590 - val_loss: 0.1221 - val_dense_1_loss: 0.2193 - val_dense_2_loss: 0.0809 - val_dense_3_loss: 0.0740 - val_dense_1_acc: 0.9403 - val_dense_2_acc: 0.9823 - val_dense_3_acc: 0.9817\n",
      "Epoch 12/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 1.0175 - dense_1_loss: 1.3896 - dense_2_loss: 0.7708 - dense_3_loss: 0.5201 - dense_1_acc: 0.6785 - dense_2_acc: 0.8216 - dense_3_acc: 0.8621 - val_loss: 0.1045 - val_dense_1_loss: 0.2060 - val_dense_2_loss: 0.0938 - val_dense_3_loss: 0.0665 - val_dense_1_acc: 0.9460 - val_dense_2_acc: 0.9828 - val_dense_3_acc: 0.9841\n",
      "Epoch 13/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 1.0038 - dense_1_loss: 1.3684 - dense_2_loss: 0.7626 - dense_3_loss: 0.5161 - dense_1_acc: 0.6832 - dense_2_acc: 0.8279 - dense_3_acc: 0.8646 - val_loss: 0.1386 - val_dense_1_loss: 0.2295 - val_dense_2_loss: 0.0845 - val_dense_3_loss: 0.0756 - val_dense_1_acc: 0.9413 - val_dense_2_acc: 0.9850 - val_dense_3_acc: 0.9845\n",
      "Epoch 14/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.9855 - dense_1_loss: 1.3381 - dense_2_loss: 0.7547 - dense_3_loss: 0.5110 - dense_1_acc: 0.6884 - dense_2_acc: 0.8355 - dense_3_acc: 0.8686 - val_loss: 0.1339 - val_dense_1_loss: 0.2022 - val_dense_2_loss: 0.0847 - val_dense_3_loss: 0.0653 - val_dense_1_acc: 0.9471 - val_dense_2_acc: 0.9849 - val_dense_3_acc: 0.9849\n",
      "Epoch 15/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.9714 - dense_1_loss: 1.3155 - dense_2_loss: 0.7469 - dense_3_loss: 0.5079 - dense_1_acc: 0.6961 - dense_2_acc: 0.8396 - dense_3_acc: 0.8692 - val_loss: 0.1168 - val_dense_1_loss: 0.1828 - val_dense_2_loss: 0.0691 - val_dense_3_loss: 0.0611 - val_dense_1_acc: 0.9501 - val_dense_2_acc: 0.9855 - val_dense_3_acc: 0.9853\n",
      "Epoch 16/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.9574 - dense_1_loss: 1.2935 - dense_2_loss: 0.7398 - dense_3_loss: 0.5029 - dense_1_acc: 0.7000 - dense_2_acc: 0.8449 - dense_3_acc: 0.8725 - val_loss: 0.1028 - val_dense_1_loss: 0.1924 - val_dense_2_loss: 0.0658 - val_dense_3_loss: 0.0605 - val_dense_1_acc: 0.9482 - val_dense_2_acc: 0.9846 - val_dense_3_acc: 0.9841\n",
      "Epoch 17/80\n",
      "707/707 [==============================] - 618s 875ms/step - loss: 0.9407 - dense_1_loss: 1.2664 - dense_2_loss: 0.7334 - dense_3_loss: 0.4965 - dense_1_acc: 0.7039 - dense_2_acc: 0.8481 - dense_3_acc: 0.8779 - val_loss: 0.0841 - val_dense_1_loss: 0.1925 - val_dense_2_loss: 0.0656 - val_dense_3_loss: 0.0577 - val_dense_1_acc: 0.9478 - val_dense_2_acc: 0.9853 - val_dense_3_acc: 0.9844\n",
      "Epoch 18/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.9302 - dense_1_loss: 1.2498 - dense_2_loss: 0.7288 - dense_3_loss: 0.4923 - dense_1_acc: 0.7094 - dense_2_acc: 0.8544 - dense_3_acc: 0.8805 - val_loss: 0.0978 - val_dense_1_loss: 0.1895 - val_dense_2_loss: 0.0648 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9467 - val_dense_2_acc: 0.9841 - val_dense_3_acc: 0.9851\n",
      "Epoch 19/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.9179 - dense_1_loss: 1.2299 - dense_2_loss: 0.7221 - dense_3_loss: 0.4895 - dense_1_acc: 0.7158 - dense_2_acc: 0.8580 - dense_3_acc: 0.8818 - val_loss: 0.0852 - val_dense_1_loss: 0.1801 - val_dense_2_loss: 0.0730 - val_dense_3_loss: 0.0584 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9864 - val_dense_3_acc: 0.9853\n",
      "Epoch 20/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.9078 - dense_1_loss: 1.2141 - dense_2_loss: 0.7170 - dense_3_loss: 0.4861 - dense_1_acc: 0.7182 - dense_2_acc: 0.8603 - dense_3_acc: 0.8841 - val_loss: 0.1027 - val_dense_1_loss: 0.1928 - val_dense_2_loss: 0.0768 - val_dense_3_loss: 0.0579 - val_dense_1_acc: 0.9493 - val_dense_2_acc: 0.9851 - val_dense_3_acc: 0.9865\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 618s 875ms/step - loss: 0.8962 - dense_1_loss: 1.1957 - dense_2_loss: 0.7115 - dense_3_loss: 0.4819 - dense_1_acc: 0.7240 - dense_2_acc: 0.8653 - dense_3_acc: 0.8887 - val_loss: 0.1008 - val_dense_1_loss: 0.1745 - val_dense_2_loss: 0.0569 - val_dense_3_loss: 0.0549 - val_dense_1_acc: 0.9521 - val_dense_2_acc: 0.9865 - val_dense_3_acc: 0.9863\n",
      "Epoch 22/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8845 - dense_1_loss: 1.1768 - dense_2_loss: 0.7066 - dense_3_loss: 0.4779 - dense_1_acc: 0.7316 - dense_2_acc: 0.8695 - dense_3_acc: 0.8906 - val_loss: 0.1158 - val_dense_1_loss: 0.1852 - val_dense_2_loss: 0.0679 - val_dense_3_loss: 0.0602 - val_dense_1_acc: 0.9528 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9857\n",
      "Epoch 23/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.8814 - dense_1_loss: 1.1722 - dense_2_loss: 0.7041 - dense_3_loss: 0.4770 - dense_1_acc: 0.7325 - dense_2_acc: 0.8719 - dense_3_acc: 0.8934 - val_loss: 0.0891 - val_dense_1_loss: 0.1841 - val_dense_2_loss: 0.0628 - val_dense_3_loss: 0.0580 - val_dense_1_acc: 0.9499 - val_dense_2_acc: 0.9868 - val_dense_3_acc: 0.9848\n",
      "Epoch 24/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8752 - dense_1_loss: 1.1621 - dense_2_loss: 0.7006 - dense_3_loss: 0.4758 - dense_1_acc: 0.7367 - dense_2_acc: 0.8745 - dense_3_acc: 0.8956 - val_loss: 0.1366 - val_dense_1_loss: 0.1726 - val_dense_2_loss: 0.0694 - val_dense_3_loss: 0.0574 - val_dense_1_acc: 0.9539 - val_dense_2_acc: 0.9851 - val_dense_3_acc: 0.9872\n",
      "Epoch 25/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.8633 - dense_1_loss: 1.1423 - dense_2_loss: 0.6981 - dense_3_loss: 0.4704 - dense_1_acc: 0.7421 - dense_2_acc: 0.8766 - dense_3_acc: 0.8990 - val_loss: 0.1101 - val_dense_1_loss: 0.1809 - val_dense_2_loss: 0.0668 - val_dense_3_loss: 0.0635 - val_dense_1_acc: 0.9515 - val_dense_2_acc: 0.9852 - val_dense_3_acc: 0.9840\n",
      "Epoch 26/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8606 - dense_1_loss: 1.1385 - dense_2_loss: 0.6949 - dense_3_loss: 0.4704 - dense_1_acc: 0.7453 - dense_2_acc: 0.8790 - dense_3_acc: 0.8990 - val_loss: 0.1022 - val_dense_1_loss: 0.1694 - val_dense_2_loss: 0.0599 - val_dense_3_loss: 0.0543 - val_dense_1_acc: 0.9550 - val_dense_2_acc: 0.9863 - val_dense_3_acc: 0.9859\n",
      "Epoch 27/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.8550 - dense_1_loss: 1.1299 - dense_2_loss: 0.6918 - dense_3_loss: 0.4683 - dense_1_acc: 0.7469 - dense_2_acc: 0.8813 - dense_3_acc: 0.9027 - val_loss: 0.0950 - val_dense_1_loss: 0.1751 - val_dense_2_loss: 0.0616 - val_dense_3_loss: 0.0535 - val_dense_1_acc: 0.9529 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9869\n",
      "Epoch 28/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8471 - dense_1_loss: 1.1178 - dense_2_loss: 0.6871 - dense_3_loss: 0.4658 - dense_1_acc: 0.7498 - dense_2_acc: 0.8851 - dense_3_acc: 0.9038 - val_loss: 0.0892 - val_dense_1_loss: 0.1805 - val_dense_2_loss: 0.0623 - val_dense_3_loss: 0.0542 - val_dense_1_acc: 0.9533 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9866\n",
      "Epoch 29/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.8418 - dense_1_loss: 1.1083 - dense_2_loss: 0.6857 - dense_3_loss: 0.4650 - dense_1_acc: 0.7543 - dense_2_acc: 0.8855 - dense_3_acc: 0.9065 - val_loss: 0.1067 - val_dense_1_loss: 0.1753 - val_dense_2_loss: 0.0758 - val_dense_3_loss: 0.0497 - val_dense_1_acc: 0.9544 - val_dense_2_acc: 0.9876 - val_dense_3_acc: 0.9874\n",
      "Epoch 30/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8349 - dense_1_loss: 1.0969 - dense_2_loss: 0.6832 - dense_3_loss: 0.4626 - dense_1_acc: 0.7586 - dense_2_acc: 0.8871 - dense_3_acc: 0.9056 - val_loss: 0.1077 - val_dense_1_loss: 0.1811 - val_dense_2_loss: 0.0598 - val_dense_3_loss: 0.0548 - val_dense_1_acc: 0.9528 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9879\n",
      "Epoch 31/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8334 - dense_1_loss: 1.0963 - dense_2_loss: 0.6806 - dense_3_loss: 0.4603 - dense_1_acc: 0.7590 - dense_2_acc: 0.8896 - dense_3_acc: 0.9091 - val_loss: 0.1314 - val_dense_1_loss: 0.1766 - val_dense_2_loss: 0.0607 - val_dense_3_loss: 0.0492 - val_dense_1_acc: 0.9539 - val_dense_2_acc: 0.9870 - val_dense_3_acc: 0.9870\n",
      "Epoch 32/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.8240 - dense_1_loss: 1.0785 - dense_2_loss: 0.6805 - dense_3_loss: 0.4586 - dense_1_acc: 0.7652 - dense_2_acc: 0.8899 - dense_3_acc: 0.9094 - val_loss: 0.0943 - val_dense_1_loss: 0.1660 - val_dense_2_loss: 0.0578 - val_dense_3_loss: 0.0510 - val_dense_1_acc: 0.9552 - val_dense_2_acc: 0.9874 - val_dense_3_acc: 0.9871\n",
      "Epoch 33/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 0.8178 - dense_1_loss: 1.0700 - dense_2_loss: 0.6754 - dense_3_loss: 0.4558 - dense_1_acc: 0.7670 - dense_2_acc: 0.8922 - dense_3_acc: 0.9112 - val_loss: 0.1035 - val_dense_1_loss: 0.1778 - val_dense_2_loss: 0.0550 - val_dense_3_loss: 0.0526 - val_dense_1_acc: 0.9530 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9867\n",
      "Epoch 34/80\n",
      "707/707 [==============================] - 620s 877ms/step - loss: 0.8147 - dense_1_loss: 1.0645 - dense_2_loss: 0.6728 - dense_3_loss: 0.4571 - dense_1_acc: 0.7690 - dense_2_acc: 0.8939 - dense_3_acc: 0.9135 - val_loss: 0.1005 - val_dense_1_loss: 0.1679 - val_dense_2_loss: 0.0587 - val_dense_3_loss: 0.0531 - val_dense_1_acc: 0.9545 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9871\n",
      "Epoch 35/80\n",
      "707/707 [==============================] - 620s 877ms/step - loss: 0.8086 - dense_1_loss: 1.0552 - dense_2_loss: 0.6710 - dense_3_loss: 0.4531 - dense_1_acc: 0.7708 - dense_2_acc: 0.8949 - dense_3_acc: 0.9136 - val_loss: 0.0781 - val_dense_1_loss: 0.1693 - val_dense_2_loss: 0.0700 - val_dense_3_loss: 0.0524 - val_dense_1_acc: 0.9557 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9866\n",
      "Epoch 36/80\n",
      "707/707 [==============================] - 618s 875ms/step - loss: 0.8037 - dense_1_loss: 1.0476 - dense_2_loss: 0.6680 - dense_3_loss: 0.4516 - dense_1_acc: 0.7749 - dense_2_acc: 0.8972 - dense_3_acc: 0.9161 - val_loss: 0.1078 - val_dense_1_loss: 0.1799 - val_dense_2_loss: 0.0647 - val_dense_3_loss: 0.0618 - val_dense_1_acc: 0.9529 - val_dense_2_acc: 0.9875 - val_dense_3_acc: 0.9860\n",
      "Epoch 37/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7990 - dense_1_loss: 1.0397 - dense_2_loss: 0.6661 - dense_3_loss: 0.4506 - dense_1_acc: 0.7793 - dense_2_acc: 0.8999 - dense_3_acc: 0.9159 - val_loss: 0.0861 - val_dense_1_loss: 0.1681 - val_dense_2_loss: 0.0556 - val_dense_3_loss: 0.0524 - val_dense_1_acc: 0.9561 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9870\n",
      "Epoch 38/80\n",
      "707/707 [==============================] - 618s 875ms/step - loss: 0.7986 - dense_1_loss: 1.0400 - dense_2_loss: 0.6650 - dense_3_loss: 0.4494 - dense_1_acc: 0.7797 - dense_2_acc: 0.9008 - dense_3_acc: 0.9178 - val_loss: 0.0889 - val_dense_1_loss: 0.1825 - val_dense_2_loss: 0.0611 - val_dense_3_loss: 0.0526 - val_dense_1_acc: 0.9515 - val_dense_2_acc: 0.9880 - val_dense_3_acc: 0.9883\n",
      "Epoch 39/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7932 - dense_1_loss: 1.0302 - dense_2_loss: 0.6636 - dense_3_loss: 0.4490 - dense_1_acc: 0.7832 - dense_2_acc: 0.9030 - dense_3_acc: 0.9188 - val_loss: 0.0910 - val_dense_1_loss: 0.1650 - val_dense_2_loss: 0.0570 - val_dense_3_loss: 0.0489 - val_dense_1_acc: 0.9571 - val_dense_2_acc: 0.9867 - val_dense_3_acc: 0.9888\n",
      "Epoch 40/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7893 - dense_1_loss: 1.0252 - dense_2_loss: 0.6613 - dense_3_loss: 0.4455 - dense_1_acc: 0.7823 - dense_2_acc: 0.9026 - dense_3_acc: 0.9207 - val_loss: 0.1080 - val_dense_1_loss: 0.1746 - val_dense_2_loss: 0.0549 - val_dense_3_loss: 0.0526 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9879 - val_dense_3_acc: 0.9862\n",
      "Epoch 41/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7840 - dense_1_loss: 1.0162 - dense_2_loss: 0.6592 - dense_3_loss: 0.4444 - dense_1_acc: 0.7879 - dense_2_acc: 0.9046 - dense_3_acc: 0.9204 - val_loss: 0.0898 - val_dense_1_loss: 0.1689 - val_dense_2_loss: 0.0605 - val_dense_3_loss: 0.0549 - val_dense_1_acc: 0.9559 - val_dense_2_acc: 0.9866 - val_dense_3_acc: 0.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80\n",
      "707/707 [==============================] - 620s 877ms/step - loss: 0.7798 - dense_1_loss: 1.0085 - dense_2_loss: 0.6580 - dense_3_loss: 0.4444 - dense_1_acc: 0.7901 - dense_2_acc: 0.9048 - dense_3_acc: 0.9227 - val_loss: 0.1180 - val_dense_1_loss: 0.1786 - val_dense_2_loss: 0.0549 - val_dense_3_loss: 0.0552 - val_dense_1_acc: 0.9533 - val_dense_2_acc: 0.9881 - val_dense_3_acc: 0.9875\n",
      "Epoch 43/80\n",
      "267/707 [==========>...................] - ETA: 6:10 - loss: 0.7794 - dense_1_loss: 1.0072 - dense_2_loss: 0.6549 - dense_3_loss: 0.4486 - dense_1_acc: 0.7913 - dense_2_acc: 0.9033 - dense_3_acc: 0.9216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7726 - dense_1_loss: 0.9976 - dense_2_loss: 0.6534 - dense_3_loss: 0.4418 - dense_1_acc: 0.7950 - dense_2_acc: 0.9073 - dense_3_acc: 0.9272 - val_loss: 0.1271 - val_dense_1_loss: 0.1948 - val_dense_2_loss: 0.0576 - val_dense_3_loss: 0.0497 - val_dense_1_acc: 0.9534 - val_dense_2_acc: 0.9864 - val_dense_3_acc: 0.9874\n",
      "Epoch 46/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7700 - dense_1_loss: 0.9940 - dense_2_loss: 0.6509 - dense_3_loss: 0.4413 - dense_1_acc: 0.7967 - dense_2_acc: 0.9100 - dense_3_acc: 0.9264 - val_loss: 0.0827 - val_dense_1_loss: 0.1831 - val_dense_2_loss: 0.0610 - val_dense_3_loss: 0.0507 - val_dense_1_acc: 0.9525 - val_dense_2_acc: 0.9862 - val_dense_3_acc: 0.9874\n",
      "Epoch 47/80\n",
      "707/707 [==============================] - 620s 877ms/step - loss: 0.7637 - dense_1_loss: 0.9828 - dense_2_loss: 0.6505 - dense_3_loss: 0.4387 - dense_1_acc: 0.7985 - dense_2_acc: 0.9089 - dense_3_acc: 0.9279 - val_loss: 0.1012 - val_dense_1_loss: 0.1694 - val_dense_2_loss: 0.0581 - val_dense_3_loss: 0.0477 - val_dense_1_acc: 0.9552 - val_dense_2_acc: 0.9863 - val_dense_3_acc: 0.9878\n",
      "Epoch 48/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7623 - dense_1_loss: 0.9815 - dense_2_loss: 0.6483 - dense_3_loss: 0.4377 - dense_1_acc: 0.8024 - dense_2_acc: 0.9114 - dense_3_acc: 0.9283 - val_loss: 0.1546 - val_dense_1_loss: 0.1836 - val_dense_2_loss: 0.0609 - val_dense_3_loss: 0.0533 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9866 - val_dense_3_acc: 0.9876\n",
      "Epoch 49/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7602 - dense_1_loss: 0.9767 - dense_2_loss: 0.6486 - dense_3_loss: 0.4388 - dense_1_acc: 0.8031 - dense_2_acc: 0.9109 - dense_3_acc: 0.9282 - val_loss: 0.0620 - val_dense_1_loss: 0.1758 - val_dense_2_loss: 0.0547 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9553 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9883\n",
      "Epoch 50/80\n",
      "707/707 [==============================] - 618s 875ms/step - loss: 0.7556 - dense_1_loss: 0.9698 - dense_2_loss: 0.6465 - dense_3_loss: 0.4362 - dense_1_acc: 0.8042 - dense_2_acc: 0.9125 - dense_3_acc: 0.9306 - val_loss: 0.0927 - val_dense_1_loss: 0.1700 - val_dense_2_loss: 0.0543 - val_dense_3_loss: 0.0516 - val_dense_1_acc: 0.9555 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9871\n",
      "Epoch 51/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7524 - dense_1_loss: 0.9644 - dense_2_loss: 0.6456 - dense_3_loss: 0.4352 - dense_1_acc: 0.8078 - dense_2_acc: 0.9127 - dense_3_acc: 0.9303 - val_loss: 0.0842 - val_dense_1_loss: 0.1769 - val_dense_2_loss: 0.0562 - val_dense_3_loss: 0.0506 - val_dense_1_acc: 0.9538 - val_dense_2_acc: 0.9868 - val_dense_3_acc: 0.9865\n",
      "Epoch 52/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7543 - dense_1_loss: 0.9675 - dense_2_loss: 0.6455 - dense_3_loss: 0.4366 - dense_1_acc: 0.8067 - dense_2_acc: 0.9137 - dense_3_acc: 0.9321 - val_loss: 0.0848 - val_dense_1_loss: 0.1892 - val_dense_2_loss: 0.0542 - val_dense_3_loss: 0.0511 - val_dense_1_acc: 0.9532 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9873\n",
      "Epoch 53/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7436 - dense_1_loss: 0.9509 - dense_2_loss: 0.6415 - dense_3_loss: 0.4309 - dense_1_acc: 0.8102 - dense_2_acc: 0.9140 - dense_3_acc: 0.9335 - val_loss: 0.0797 - val_dense_1_loss: 0.1897 - val_dense_2_loss: 0.0542 - val_dense_3_loss: 0.0538 - val_dense_1_acc: 0.9545 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9863\n",
      "Epoch 54/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7478 - dense_1_loss: 0.9575 - dense_2_loss: 0.6420 - dense_3_loss: 0.4341 - dense_1_acc: 0.8121 - dense_2_acc: 0.9157 - dense_3_acc: 0.9328 - val_loss: 0.0749 - val_dense_1_loss: 0.1830 - val_dense_2_loss: 0.0587 - val_dense_3_loss: 0.0519 - val_dense_1_acc: 0.9530 - val_dense_2_acc: 0.9860 - val_dense_3_acc: 0.9879\n",
      "Epoch 55/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.7451 - dense_1_loss: 0.9532 - dense_2_loss: 0.6427 - dense_3_loss: 0.4315 - dense_1_acc: 0.8119 - dense_2_acc: 0.9172 - dense_3_acc: 0.9340 - val_loss: 0.0711 - val_dense_1_loss: 0.1781 - val_dense_2_loss: 0.0544 - val_dense_3_loss: 0.0523 - val_dense_1_acc: 0.9556 - val_dense_2_acc: 0.9877 - val_dense_3_acc: 0.9876\n",
      "Epoch 56/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.7404 - dense_1_loss: 0.9458 - dense_2_loss: 0.6400 - dense_3_loss: 0.4299 - dense_1_acc: 0.8161 - dense_2_acc: 0.9162 - dense_3_acc: 0.9346 - val_loss: 0.0727 - val_dense_1_loss: 0.1896 - val_dense_2_loss: 0.0526 - val_dense_3_loss: 0.0518 - val_dense_1_acc: 0.9537 - val_dense_2_acc: 0.9881 - val_dense_3_acc: 0.9866\n",
      "Epoch 57/80\n",
      "707/707 [==============================] - 622s 880ms/step - loss: 0.7409 - dense_1_loss: 0.9463 - dense_2_loss: 0.6394 - dense_3_loss: 0.4315 - dense_1_acc: 0.8152 - dense_2_acc: 0.9163 - dense_3_acc: 0.9356 - val_loss: 0.0933 - val_dense_1_loss: 0.1852 - val_dense_2_loss: 0.0525 - val_dense_3_loss: 0.0510 - val_dense_1_acc: 0.9543 - val_dense_2_acc: 0.9883 - val_dense_3_acc: 0.9874\n",
      "Epoch 58/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.7357 - dense_1_loss: 0.9375 - dense_2_loss: 0.6377 - dense_3_loss: 0.4301 - dense_1_acc: 0.8213 - dense_2_acc: 0.9181 - dense_3_acc: 0.9358 - val_loss: 0.0641 - val_dense_1_loss: 0.1786 - val_dense_2_loss: 0.0518 - val_dense_3_loss: 0.0507 - val_dense_1_acc: 0.9570 - val_dense_2_acc: 0.9884 - val_dense_3_acc: 0.9881\n",
      "Epoch 59/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7320 - dense_1_loss: 0.9328 - dense_2_loss: 0.6349 - dense_3_loss: 0.4275 - dense_1_acc: 0.8194 - dense_2_acc: 0.9180 - dense_3_acc: 0.9374 - val_loss: 0.0816 - val_dense_1_loss: 0.1703 - val_dense_2_loss: 0.0537 - val_dense_3_loss: 0.0515 - val_dense_1_acc: 0.9570 - val_dense_2_acc: 0.9889 - val_dense_3_acc: 0.9867\n",
      "Epoch 60/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.7345 - dense_1_loss: 0.9359 - dense_2_loss: 0.6370 - dense_3_loss: 0.4293 - dense_1_acc: 0.8196 - dense_2_acc: 0.9197 - dense_3_acc: 0.9368 - val_loss: 0.0789 - val_dense_1_loss: 0.2073 - val_dense_2_loss: 0.0578 - val_dense_3_loss: 0.0518 - val_dense_1_acc: 0.9526 - val_dense_2_acc: 0.9878 - val_dense_3_acc: 0.9882\n",
      "Epoch 61/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7268 - dense_1_loss: 0.9234 - dense_2_loss: 0.6345 - dense_3_loss: 0.4257 - dense_1_acc: 0.8245 - dense_2_acc: 0.9209 - dense_3_acc: 0.9387 - val_loss: 0.0970 - val_dense_1_loss: 0.1937 - val_dense_2_loss: 0.0591 - val_dense_3_loss: 0.0521 - val_dense_1_acc: 0.9533 - val_dense_2_acc: 0.9875 - val_dense_3_acc: 0.9880\n",
      "Epoch 62/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7239 - dense_1_loss: 0.9187 - dense_2_loss: 0.6327 - dense_3_loss: 0.4255 - dense_1_acc: 0.8262 - dense_2_acc: 0.9196 - dense_3_acc: 0.9381 - val_loss: 0.1442 - val_dense_1_loss: 0.1845 - val_dense_2_loss: 0.0559 - val_dense_3_loss: 0.0518 - val_dense_1_acc: 0.9524 - val_dense_2_acc: 0.9861 - val_dense_3_acc: 0.9868\n",
      "Epoch 63/80\n",
      "707/707 [==============================] - 618s 875ms/step - loss: 0.7252 - dense_1_loss: 0.9221 - dense_2_loss: 0.6313 - dense_3_loss: 0.4255 - dense_1_acc: 0.8254 - dense_2_acc: 0.9221 - dense_3_acc: 0.9394 - val_loss: 0.0970 - val_dense_1_loss: 0.1868 - val_dense_2_loss: 0.0529 - val_dense_3_loss: 0.0540 - val_dense_1_acc: 0.9570 - val_dense_2_acc: 0.9883 - val_dense_3_acc: 0.9877\n",
      "Epoch 64/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7239 - dense_1_loss: 0.9184 - dense_2_loss: 0.6328 - dense_3_loss: 0.4259 - dense_1_acc: 0.8277 - dense_2_acc: 0.9214 - dense_3_acc: 0.9386 - val_loss: 0.1302 - val_dense_1_loss: 0.1858 - val_dense_2_loss: 0.0533 - val_dense_3_loss: 0.0506 - val_dense_1_acc: 0.9553 - val_dense_2_acc: 0.9878 - val_dense_3_acc: 0.9877\n",
      "Epoch 65/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7213 - dense_1_loss: 0.9148 - dense_2_loss: 0.6311 - dense_3_loss: 0.4243 - dense_1_acc: 0.8287 - dense_2_acc: 0.9220 - dense_3_acc: 0.9407 - val_loss: 0.0614 - val_dense_1_loss: 0.1717 - val_dense_2_loss: 0.0557 - val_dense_3_loss: 0.0488 - val_dense_1_acc: 0.9566 - val_dense_2_acc: 0.9869 - val_dense_3_acc: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "707/707 [==============================] - 619s 876ms/step - loss: 0.7167 - dense_1_loss: 0.9080 - dense_2_loss: 0.6283 - dense_3_loss: 0.4223 - dense_1_acc: 0.8305 - dense_2_acc: 0.9230 - dense_3_acc: 0.9388 - val_loss: 0.1179 - val_dense_1_loss: 0.1827 - val_dense_2_loss: 0.0681 - val_dense_3_loss: 0.0551 - val_dense_1_acc: 0.9551 - val_dense_2_acc: 0.9873 - val_dense_3_acc: 0.9870\n",
      "Epoch 67/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7182 - dense_1_loss: 0.9094 - dense_2_loss: 0.6301 - dense_3_loss: 0.4238 - dense_1_acc: 0.8306 - dense_2_acc: 0.9241 - dense_3_acc: 0.9409 - val_loss: 0.0882 - val_dense_1_loss: 0.1787 - val_dense_2_loss: 0.0513 - val_dense_3_loss: 0.0471 - val_dense_1_acc: 0.9567 - val_dense_2_acc: 0.9878 - val_dense_3_acc: 0.9884\n",
      "Epoch 68/80\n",
      "707/707 [==============================] - 619s 875ms/step - loss: 0.7168 - dense_1_loss: 0.9081 - dense_2_loss: 0.6278 - dense_3_loss: 0.4232 - dense_1_acc: 0.8307 - dense_2_acc: 0.9254 - dense_3_acc: 0.9414 - val_loss: 0.1148 - val_dense_1_loss: 0.1821 - val_dense_2_loss: 0.0550 - val_dense_3_loss: 0.0478 - val_dense_1_acc: 0.9576 - val_dense_2_acc: 0.9884 - val_dense_3_acc: 0.9888\n",
      "Epoch 69/80\n",
      "707/707 [==============================] - 618s 874ms/step - loss: 0.7109 - dense_1_loss: 0.8983 - dense_2_loss: 0.6262 - dense_3_loss: 0.4208 - dense_1_acc: 0.8331 - dense_2_acc: 0.9250 - dense_3_acc: 0.9423 - val_loss: 0.0855 - val_dense_1_loss: 0.1980 - val_dense_2_loss: 0.0552 - val_dense_3_loss: 0.0515 - val_dense_1_acc: 0.9549 - val_dense_2_acc: 0.9879 - val_dense_3_acc: 0.9881\n",
      "Epoch 71/80\n",
      "707/707 [==============================] - 620s 878ms/step - loss: 0.7093 - dense_1_loss: 0.8959 - dense_2_loss: 0.6251 - dense_3_loss: 0.4205 - dense_1_acc: 0.8357 - dense_2_acc: 0.9248 - dense_3_acc: 0.9420 - val_loss: 0.1029 - val_dense_1_loss: 0.2004 - val_dense_2_loss: 0.0545 - val_dense_3_loss: 0.0517 - val_dense_1_acc: 0.9542 - val_dense_2_acc: 0.9879 - val_dense_3_acc: 0.9881\n",
      "Epoch 72/80\n",
      "707/707 [==============================] - 620s 876ms/step - loss: 0.7107 - dense_1_loss: 0.8979 - dense_2_loss: 0.6266 - dense_3_loss: 0.4202 - dense_1_acc: 0.8355 - dense_2_acc: 0.9246 - dense_3_acc: 0.9419 - val_loss: 0.0832 - val_dense_1_loss: 0.2407 - val_dense_2_loss: 0.0661 - val_dense_3_loss: 0.0665 - val_dense_1_acc: 0.9501 - val_dense_2_acc: 0.9868 - val_dense_3_acc: 0.9852\n",
      "Epoch 73/80\n",
      "604/707 [========================>.....] - ETA: 1:27 - loss: 0.7056 - dense_1_loss: 0.8890 - dense_2_loss: 0.6247 - dense_3_loss: 0.4199 - dense_1_acc: 0.8387 - dense_2_acc: 0.9247 - dense_3_acc: 0.9429"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "train_gen = DataLoader(X_train, y_train, training=True, batch_size=batch_size,size=size)\n",
    "valid_gen = DataLoader(X_test, y_test, training=False, batch_size=batch_size,size=size)\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = getMultiBased()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[0.5,0.25,0.25])\n",
    "print(\"compiled\")\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, epochs=80, callbacks=[checkpoint], workers=64, use_multiprocessing=True)\n",
    "model.save(\"multiXception.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
