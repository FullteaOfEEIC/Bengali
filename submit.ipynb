{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import scipy.stats as stats\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.backend import clear_session\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from six.moves import xrange\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras_applications.imagenet_utils import decode_predictions\n",
    "from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n",
    "import keras\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]\n",
    "\n",
    "def upper(img,mergin=5):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[up:mid,:])==0:\n",
    "            up=mid\n",
    "        else:\n",
    "            bottom=mid\n",
    "    return max(up-mergin,0)\n",
    "\n",
    "def lower(img,mergin=5):\n",
    "    up=0\n",
    "    bottom=img.shape[0]\n",
    "    while bottom-up>2:\n",
    "        mid=(up+bottom)//2\n",
    "        if np.sum(img[mid:bottom,:])==0:\n",
    "            bottom=mid\n",
    "        else:\n",
    "            up=mid\n",
    "    return min(bottom+mergin,img.shape[0])\n",
    "\n",
    "def lefter(img,mergin=5):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,left:mid])==0:\n",
    "            left=mid\n",
    "        else:\n",
    "            right=mid\n",
    "    return max(left-mergin,0)\n",
    "\n",
    "def righter(img,mergin=5):\n",
    "    left=0\n",
    "    right=img.shape[1]\n",
    "    while right-left>2:\n",
    "        mid=(left+right)//2\n",
    "        if np.sum(img[:,mid:right])==0:\n",
    "            right=mid\n",
    "        else:\n",
    "            left=mid\n",
    "    return min(right+mergin,img.shape[1])\n",
    "\n",
    "def transformImg(img,size,tta=False,trim=\"edge\"):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if tta:\n",
    "        img = affine_image(img)\n",
    "    if trim==\"edge\":\n",
    "        img = img[upper(img):lower(img),lefter(img):righter(img)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "\n",
    "def affine_image(img):\n",
    "    # ch, h, w = img.shape\n",
    "    # img = img / 255.\n",
    "    if img.ndim == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    # --- scale ---\n",
    "    min_scale = 0.8\n",
    "    max_scale = 1.2\n",
    "    sx = np.random.uniform(min_scale, max_scale)\n",
    "    sy = np.random.uniform(min_scale, max_scale)\n",
    "\n",
    "    # --- rotation ---\n",
    "    max_rot_angle = 7\n",
    "    rot_angle = np.random.uniform(-max_rot_angle, max_rot_angle) * np.pi / 180.\n",
    "\n",
    "    # --- shear ---\n",
    "    max_shear_angle = 10\n",
    "    shear_angle = np.random.uniform(-max_shear_angle, max_shear_angle) * np.pi / 180.\n",
    "\n",
    "    # --- translation ---\n",
    "    max_translation = 4\n",
    "    tx = np.random.randint(-max_translation, max_translation)\n",
    "    ty = np.random.randint(-max_translation, max_translation)\n",
    "\n",
    "    tform = AffineTransform(scale=(sx, sy), rotation=rot_angle, shear=shear_angle,\n",
    "                            translation=(tx, ty))\n",
    "    transformed_image = warp(img, tform)\n",
    "    assert transformed_image.ndim == 2\n",
    "    return (transformed_image*255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(224,224),tta=False,trim=\"edge\"):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.tta=tta\n",
    "        self.trim=trim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        _imgs=self.X[i * self.batch_size:(i + 1) * self.batch_size,:,:]\n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,tta=self.tta,trim=self.trim))\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label,cat in zip(labels,[168,11,7]):\n",
    "            ret_y.append(to_categorical(self.y[i * self.batch_size:(i + 1) * self.batch_size],num_classes=cat))\n",
    "    \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    models = kwargs.get('models', _KERAS_MODELS)\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils\n",
    "\n",
    "\n",
    "def inject_keras_modules(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        kwargs['backend'] = keras.backend\n",
    "        kwargs['layers'] = keras.layers\n",
    "        kwargs['models'] = keras.models\n",
    "        kwargs['utils'] = keras.utils\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    kwargs = {k: v for k, v in kwargs.items() if k in ['backend', 'layers', 'models', 'utils']}\n",
    "    return _preprocess_input(x, mode='torch', **kwargs)\n",
    "\n",
    "\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "    def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            try:\n",
    "                # The native TF implementation has a more\n",
    "                # memory-efficient gradient implementation\n",
    "                return backend.tf.nn.swish(x)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return x * backend.sigmoid(x)\n",
    "    return  swish\n",
    "\n",
    "\n",
    "def get_dropout(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "    class FixedDropout(layers.Dropout):\n",
    "        def _get_noise_shape(self, inputs):\n",
    "            if self.noise_shape is None:\n",
    "                return self.noise_shape\n",
    "\n",
    "            symbolic_shape = backend.shape(inputs)\n",
    "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                           for axis, shape in enumerate(self.noise_shape)]\n",
    "            return tuple(noise_shape)\n",
    "\n",
    "    return FixedDropout\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tta=False\n",
    "folderName=\".\"\n",
    "\n",
    "if tta:\n",
    "    repeat=3\n",
    "else:\n",
    "    repeat=1\n",
    "\n",
    "custom_objects= {'swish': inject_keras_modules(get_swish)(),'FixedDropout': inject_keras_modules(get_dropout)(),\"tf\":tf,\"gm_exp\":gm_exp}\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    table = pq.read_table('./data/test_image_data_{0}.parquet'.format(i))\n",
    "    dfEval = table.to_pandas()\n",
    "    del table\n",
    "    dfEval = dfEval.set_index(\"image_id\")\n",
    "    imgs = dfEval.values.reshape(-1,137,236)\n",
    "\n",
    "    ans = pd.DataFrame(index=dfEval.index)\n",
    "    del dfEval\n",
    "    y_preds={\"grapheme_root\":[],\"vowel_diacritic\":[],\"consonant_diacritic\":[]}\n",
    "    for file in tqdm([\"multiEFFB0-justresize.h5\"]):\n",
    "        model = load_model(\"{0}/{1}\".format(folderName, file),custom_objects =custom_objects, compile=False)\n",
    "        #model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[2.,1.,1.])\n",
    "        size = (model.input.shape[1],model.input.shape[2])\n",
    "        print(file,size)\n",
    "        for j in range(repeat):\n",
    "            test_gen = DataLoader(imgs, [0]*imgs.shape[0], training=False, batch_size=128,size=size,tta=tta,trim=None)\n",
    "            y_pred = model.predict(test_gen,verbose=1)\n",
    "            #y_pred = np.argmax(y_pred, axis=1)\n",
    "            for k,label in enumerate([\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]):\n",
    "                tmp = y_preds[label]\n",
    "                tmp.append(y_pred[k])\n",
    "                y_preds[label]=tmp\n",
    "        del model\n",
    "        clear_session()\n",
    "    for key in y_preds:\n",
    "        y_pred = np.asarray(y_preds[key])\n",
    "        #y_pred, _ = stats.mode(y_preds,axis=0)\n",
    "        #y_pred = y_pred.reshape(-1,)\n",
    "        y_pred = np.mean(y_preds[key],axis=0)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        ans[key] = y_pred\n",
    "    del y_preds\n",
    "    with open(\"tmp{}.csv\".format(i), \"w\") as fp:\n",
    "        for row_id,consonant,grapheme,vowel in zip(ans.index, ans[\"consonant_diacritic\"],ans[\"grapheme_root\"],ans[\"vowel_diacritic\"]):\n",
    "            fp.write(\"{0}_grapheme_root,{1}\\n\".format(row_id,grapheme))\n",
    "            fp.write(\"{0}_vowel_diacritic,{1}\\n\".format(row_id,vowel))\n",
    "            fp.write(\"{0}_consonant_diacritic,{1}\\n\".format(row_id,consonant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
