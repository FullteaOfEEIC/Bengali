{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, PReLU, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, Sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/train.csv\")\n",
    "yEval = pd.read_csv(\"data/test.csv\")\n",
    "classMap = pd.read_csv(\"data/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pq.read_table('data/train_image_data_{0}.parquet'.format(i)).to_pandas() for i in range(4)]\n",
    "df = pd.concat(tables)\n",
    "df = df.set_index(\"image_id\")\n",
    "del tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    def __init__(self,X,y,training,batch_size=64,size=(255,255),alpha=3,transform=None,trim=\"edge\"):\n",
    "        self.training = training\n",
    "        self.batch_size=batch_size\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.size=size\n",
    "        self.alpha=alpha\n",
    "        self.transform=transform\n",
    "        self.trim=trim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        _imgs=self.X[idx * self.batch_size:(idx + 1) * self.batch_size,:,:]\n",
    "        \n",
    "        imgs=[]\n",
    "        for img in _imgs:\n",
    "            imgs.append(transformImg(img,size=self.size,training=self.training,trim=self.trim))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            _imgs=[]\n",
    "            for img in imgs:\n",
    "                if np.random.random()<0.5:\n",
    "                    res = self.transform(image=img)\n",
    "                    img = res['image'].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "                _imgs.append(img)\n",
    "            imgs=_imgs \n",
    "        \n",
    "        imgs=np.asarray(imgs)\n",
    "        \n",
    "        \n",
    "        ret_y=[]\n",
    "        for label in labels:\n",
    "            ret_y.append(to_categorical(self.y[idx * self.batch_size:(idx + 1) * self.batch_size][label],num_classes=len(set(y[label]))))\n",
    "    \n",
    "        #mix up\n",
    "        if self.training :\n",
    "            r = np.random.permutation(imgs.shape[0])\n",
    "            imgs2=deepcopy(imgs)[r]\n",
    "            grapheme=ret_y[0]\n",
    "            vowel=ret_y[1]\n",
    "            consonant=ret_y[2]\n",
    "            grapheme2=deepcopy(grapheme)[r]\n",
    "            vowel2=deepcopy(vowel)[r]\n",
    "            consonant2=deepcopy(consonant)[r]\n",
    "            ratio=np.random.beta(self.alpha,self.alpha,imgs.shape[0])\n",
    "            ratio[ratio>1]=1\n",
    "            ratio[ratio<0]=0\n",
    "            imgs=np.tile(ratio,(3,*size,1)).T*imgs+np.tile((1-ratio),(3,*size,1)).T*imgs2\n",
    "            grapheme=np.tile(ratio,(168,1)).T*grapheme+np.tile((1-ratio),(168,1)).T*grapheme2\n",
    "            vowel=np.tile(ratio,(11,1)).T*vowel+np.tile((1-ratio),(11,1)).T*vowel2\n",
    "            consonant=np.tile(ratio,(7,1)).T*consonant+np.tile((1-ratio),(7,1)).T*consonant2\n",
    "            grapheme=grapheme.astype(np.float32)\n",
    "            vowel=vowel.astype(np.float32)\n",
    "            consonant=consonant.astype(np.float32)\n",
    "            ret_y=[grapheme,vowel,consonant]\n",
    "   \n",
    "        if self.training:\n",
    "            imgs = [cutout(img) for img in imgs]\n",
    "            pass\n",
    "            \n",
    "        imgs = np.asarray(imgs).astype(np.float32)/255.0\n",
    "            \n",
    "\n",
    "        return imgs, ret_y\n",
    "\n",
    "def transformImg(img,size=(255,255),training=True,clahe=False,mergin=5,trim=\"edge\"):\n",
    "    ret2, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "    img = 255-img\n",
    "    if training:\n",
    "        img=affine_image(img)\n",
    "    if trim==\"edge\":\n",
    "        img = img[upper(img,mergin):lower(img,mergin),lefter(img,mergin):righter(img,mergin)]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img, (size[0],size[1]))\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return img\n",
    "\n",
    "def cutout(image_origin):\n",
    "    # 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
    "    image = np.copy(image_origin)\n",
    "    mask_value = image.mean()\n",
    "\n",
    "    h, w, c = image.shape\n",
    "    # マスクをかける場所のtop, leftをランダムに決める\n",
    "    # はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
    "    mask_size=h//2\n",
    "    top = np.random.randint(0 - mask_size // 2, h - mask_size)\n",
    "    left = np.random.randint(0 - mask_size // 2, w - mask_size)\n",
    "    bottom = top + mask_size\n",
    "    right = left + mask_size\n",
    "\n",
    "    # はみ出した場合の処理\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "\n",
    "    # マスク部分の画素値を平均値で埋める\n",
    "    image[top:bottom, left:right, :].fill(mask_value)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236), y, train_size=0.9, random_state=8888)\n",
    "gen = DataLoader(X_test, y_test, training=False, batch_size=512, size=size,trim=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values.reshape(-1,137,236), y, train_size=0.9, random_state=8000)\n",
    "gen2 = DataLoader(X_test, y_test, training=False, batch_size=512, size=size,trim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 382s 10s/step\n",
      "[0.05067349225282669, 0.083149753510952, 0.03222891315817833, 0.029337456449866295, 0.9748058319091797, 0.9920334815979004, 0.9917347431182861]\n",
      "40/40 [==============================] - 374s 9s/step\n",
      "[0.42937761545181274, 0.14010223746299744, 0.047822363674640656, 0.04180247336626053, 0.9602170586585999, 0.9891455769538879, 0.9890459775924683]\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"multiRes152V2-justresize.h5\",compile=False)\n",
    "model.compile(optimizer=Adam(), metrics=[\"acc\"], loss=\"categorical_crossentropy\", loss_weights=[2.,1.,1.])\n",
    "print(model.evaluate(gen,verbose=1))\n",
    "print(model.evaluate(gen2,verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"multiRes152V2-justresize.h5\",include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "    def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            try:\n",
    "                # The native TF implementation has a more\n",
    "                # memory-efficient gradient implementation\n",
    "                return backend.tf.nn.swish(x)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return x * backend.sigmoid(x)\n",
    "    return  swish\n",
    "\n",
    "\n",
    "def get_dropout(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "    class FixedDropout(layers.Dropout):\n",
    "        def _get_noise_shape(self, inputs):\n",
    "            if self.noise_shape is None:\n",
    "                return self.noise_shape\n",
    "\n",
    "            symbolic_shape = backend.shape(inputs)\n",
    "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                           for axis, shape in enumerate(self.noise_shape)]\n",
    "            return tuple(noise_shape)\n",
    "\n",
    "    return FixedDropout\n",
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    models = kwargs.get('models', _KERAS_MODELS)\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils\n",
    "\n",
    "\n",
    "def inject_keras_modules(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        kwargs['backend'] = keras.backend\n",
    "        kwargs['layers'] = keras.layers\n",
    "        kwargs['models'] = keras.models\n",
    "        kwargs['utils'] = keras.utils\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "def generalized_mean_pool_2d(X):\n",
    "    import tensorflow as tf\n",
    "    gm_exp = tf.Variable(3.0, dtype = tf.float32)\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "                        axis = [1, 2], \n",
    "                        keepdims = False) + 1.e-7)**(1./gm_exp)\n",
    "    return pool\n",
    "\n",
    "\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects= {'swish': inject_keras_modules(get_swish)(),'FixedDropout': inject_keras_modules(get_dropout)(),\"tf\":tf,\"gm_exp\":gm_exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
